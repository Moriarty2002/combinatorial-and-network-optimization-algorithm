{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9903b1c7",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b59b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMAL_SOLUTION = 0 # used to evaluate gap between math model and heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28210e55",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6217fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_video = 0\n",
    "num_endpoint = 0\n",
    "num_req_descriptions = 0\n",
    "num_server = 0\n",
    "\n",
    "cache_capacity = 0\n",
    "video_size = []\n",
    "\n",
    "latency = defaultdict(lambda: defaultdict(int))     # [endpoint][cache/datacenter] = latency\n",
    "reqs = defaultdict(lambda: defaultdict(int))        # [endpoint][video] = num reqs\n",
    "\n",
    "# dataset = \"dataset/videos_worth_spreading.in\"\n",
    "dataset = \"dataset/me_at_the_zoo.in\"\n",
    "# dataset = \"dataset/custom.in\"\n",
    "# dataset = \"dataset/minimal.in\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85803ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 0\n",
    "curr_endpoint_index = 0\n",
    "num_connected_cache = 0\n",
    "with open(dataset, \"r\") as f:\n",
    "    for line_content in f:\n",
    "        line = line_content.split()\n",
    "\n",
    "        if status ==0:                                  # get counters\n",
    "            num_video = int(line[0])\n",
    "            num_endpoint = int(line[1])\n",
    "            num_req_descriptions = int(line[2])\n",
    "            num_server = int(line[3])\n",
    "            cache_capacity = int(line[4])\n",
    "            status = 1\n",
    "\n",
    "        elif status == 1:                               # get video dims\n",
    "            for size in line:\n",
    "                video_size.append(int(size))\n",
    "            status = 2\n",
    "\n",
    "        elif status == 2:                               # get datacenter latency and connected cache number\n",
    "            data_center_latency = int(line[0])\n",
    "            latency[curr_endpoint_index][num_server] = data_center_latency\n",
    "            \n",
    "            num_connected_cache = int(line[1])\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "            else:\n",
    "                status = 3\n",
    "        \n",
    "        elif status == 3:                                  # get cache latency\n",
    "            cache_index = int(line[0])\n",
    "            cache_latency = int(line[1])\n",
    "            latency[curr_endpoint_index][cache_index] = cache_latency\n",
    "            \n",
    "            num_connected_cache = num_connected_cache - 1\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "                else:\n",
    "                    status = 2\n",
    "        \n",
    "        elif status == 4:                                   # take num requests\n",
    "            video_index = int(line[0])\n",
    "            curr_endpoint_index = int(line[1])\n",
    "            num_reqs = int(line[2])\n",
    "            reqs[curr_endpoint_index][video_index] = num_reqs                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fb2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common indexes\n",
    "endpoint_index = range(num_endpoint)\n",
    "server_index = range(num_server + 1) # I've modelled datacenter as last server\n",
    "video_index = range(num_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861cb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num video: 100, num endpoints 10, req descriptions 100, num cache 10, dim 100\n",
      "video sized: [20, 11, 50, 26, 5, 3, 6, 32, 40, 22, 4, 20, 50, 27, 49, 44, 1, 37, 35, 27, 14, 33, 6, 22, 23, 48, 44, 14, 26, 9, 46, 44, 15, 32, 31, 8, 39, 27, 39, 27, 1, 17, 1, 47, 44, 42, 16, 3, 44, 48, 5, 25, 4, 39, 39, 7, 24, 28, 14, 44, 22, 11, 27, 37, 11, 16, 50, 33, 22, 26, 7, 12, 17, 30, 12, 12, 4, 32, 12, 46, 43, 4, 12, 34, 11, 7, 47, 29, 24, 40, 41, 10, 5, 22, 22, 24, 37, 34, 50, 5]\n",
      "latencies: defaultdict(<function <lambda> at 0x7fbe30e17100>, {0: defaultdict(<class 'int'>, {10: 1013, 0: 170, 1: 22, 2: 224}), 1: defaultdict(<class 'int'>, {10: 696, 0: 7, 1: 50}), 2: defaultdict(<class 'int'>, {10: 1114, 1: 202, 4: 175, 5: 2}), 3: defaultdict(<class 'int'>, {10: 464, 1: 24, 8: 25}), 4: defaultdict(<class 'int'>, {10: 522, 3: 216, 5: 155, 6: 139, 7: 208, 8: 145}), 5: defaultdict(<class 'int'>, {10: 321, 0: 26, 2: 70, 8: 159, 9: 92}), 6: defaultdict(<class 'int'>, {10: 1288, 2: 163, 9: 153}), 7: defaultdict(<class 'int'>, {10: 226, 7: 86}), 8: defaultdict(<class 'int'>, {10: 316, 4: 236, 5: 79, 6: 9, 7: 53, 8: 67}), 9: defaultdict(<class 'int'>, {10: 365, 2: 225, 3: 62, 5: 141, 6: 147, 9: 66})})\n",
      "reqs: defaultdict(<function <lambda> at 0x7fbe30e171a0>, {4: defaultdict(<class 'int'>, {27: 340, 24: 279, 8: 862, 3: 214, 0: 306, 2: 906, 26: 10, 54: 621}), 8: defaultdict(<class 'int'>, {13: 249, 0: 865, 3: 247, 21: 880, 1: 211, 16: 93, 30: 882, 44: 267, 4: 859}), 1: defaultdict(<class 'int'>, {1: 449, 89: 297, 0: 930, 7: 116, 5: 554, 10: 128, 46: 435}), 2: defaultdict(<class 'int'>, {0: 817, 7: 785, 81: 120, 32: 717, 8: 396, 13: 934, 17: 605, 3: 103, 10: 709}), 5: defaultdict(<class 'int'>, {1: 51, 8: 935, 19: 748, 2: 853, 5: 676, 16: 620, 82: 720}), 9: defaultdict(<class 'int'>, {0: 580, 30: 927, 16: 996, 4: 266, 2: 179, 10: 280, 5: 537, 1: 116}), 3: defaultdict(<class 'int'>, {2: 986, 34: 752, 0: 865, 3: 899, 6: 577, 16: 70, 10: 849, 1: 409}), 0: defaultdict(<class 'int'>, {31: 585, 8: 186, 13: 459, 7: 214, 99: 772, 1: 884, 15: 737, 26: 194, 65: 926}), 6: defaultdict(<class 'int'>, {8: 300, 1: 988, 62: 8, 16: 939, 0: 400, 23: 262, 4: 512, 43: 331}), 7: defaultdict(<class 'int'>, {7: 204, 1: 228, 2: 861, 74: 885, 65: 109, 5: 314, 54: 671, 11: 301})})\n"
     ]
    }
   ],
   "source": [
    "print(f\"num video: {num_video}, num endpoints {num_endpoint}, req descriptions {num_req_descriptions}, num cache {num_server}, dim {cache_capacity}\")\n",
    "print(f\"video sized: {video_size}\")\n",
    "print(f\"latencies: {latency}\")\n",
    "print(f\"reqs: {reqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922188b",
   "metadata": {},
   "source": [
    "---\n",
    "# Math model for Guroby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac327f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2635449\n",
      "Academic license - for non-commercial use only - expires 2026-03-12\n",
      "Error: invalid user locale; possible fix is to set the system environment\n",
      "       variable 'LC_ALL' to a valid locale (e.g., to 'C')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (3, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (4, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (5, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (6, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (7, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (8, 9): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 3): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 4): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 5): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 6): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 7): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 8): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (9, 9): <gurobi.Constr *Awaiting Model Update*>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gp.Model(\"YoutubeCache\")\n",
    "\n",
    "# DECISION VARS\n",
    "x = model.addVars(endpoint_index, server_index, video_index, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "y = model.addVars(server_index, video_index, vtype=gp.GRB.BINARY, name=\"y\")\n",
    "\n",
    "# OBJECTIVE FUNCTION\n",
    "obj = gp.quicksum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "# the + y[s,v] it's used just to not let place useless video in cache server (but is not needed for this problem)\n",
    "# obj = gp.quicksum((latency[e][s]*reqs[e][v]*x[e,s,v] + y[s,v])for e in endpoint_index for s in server_index for v in video_index)\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "# CONSTRAINTS\n",
    "constr = (gp.quicksum(x[e,s,v] for e in endpoint_index)  <= num_endpoint*y[s,v] for s in server_index for v in video_index )\n",
    "model.addConstrs(constr, name=\"if video v available on server s\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for s in server_index ) == (1 if reqs[e][v] else 0) for e in endpoint_index for v in video_index ) # datacenter excluded \n",
    "model.addConstrs(constr, name=\"every request must be satisfied\")\n",
    "\n",
    "constr = ( gp.quicksum(video_size[v] * y[s,v] for v in video_index) <= cache_capacity for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"cache capacity\")\n",
    "\n",
    "\n",
    "constr = ( y[num_server,v] == 1 for v in video_index ) # cache servers are from 0 to s-1, s index (num_server) is for datacenter\n",
    "model.addConstrs(constr, name=\"Datacenter have all videos\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for v in video_index ) <= (num_video*latency[e][s]) for e in endpoint_index for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"video v must be available on server s to be selected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d392c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (linux64 - \"Arch Linux\")\n",
      "\n",
      "CPU model: AMD Ryzen 7 5700U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 2310 rows, 12100 columns and 34200 nonzeros\n",
      "Model fingerprint: 0x3cddaa95\n",
      "Variable types: 0 continuous, 12100 integer (12100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+01]\n",
      "  Objective range  [2e+02, 1e+06]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Found heuristic solution: objective 1.214005e+07\n",
      "Presolve removed 2169 rows and 11778 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 141 rows, 322 columns, 633 nonzeros\n",
      "Variable types: 0 continuous, 322 integer (322 binary)\n",
      "Found heuristic solution: objective 8693972.0000\n",
      "\n",
      "Root relaxation: objective 3.127974e+06, 126 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3127974.34    0   53 8693972.00 3127974.34  64.0%     -    0s\n",
      "H    0     0                    7118653.0000 3127974.34  56.1%     -    0s\n",
      "H    0     0                    7077316.0000 3127974.34  55.8%     -    0s\n",
      "H    0     0                    6340587.0000 3127974.34  50.7%     -    0s\n",
      "H    0     0                    6039143.0000 3127974.34  48.2%     -    0s\n",
      "H    0     0                    5702303.0000 3127974.34  45.1%     -    0s\n",
      "H    0     0                    5575476.0000 3127974.34  43.9%     -    0s\n",
      "H    0     0                    5437290.0000 3127974.34  42.5%     -    0s\n",
      "H    0     0                    5432136.0000 3745000.72  31.1%     -    0s\n",
      "H    0     0                    5362994.0000 3745000.72  30.2%     -    0s\n",
      "     0     0 3745000.72    0   55 5362994.00 3745000.72  30.2%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 4055513.01    0   59 5362994.00 4055513.01  24.4%     -    0s\n",
      "H    0     0                    5296306.0000 4062646.30  23.3%     -    0s\n",
      "H    0     0                    5292854.0000 4062646.30  23.2%     -    0s\n",
      "     0     0 4062646.30    0   53 5292854.00 4062646.30  23.2%     -    0s\n",
      "H    0     0                    5027784.0000 4078856.01  18.9%     -    0s\n",
      "     0     0 4078856.01    0   84 5027784.00 4078856.01  18.9%     -    0s\n",
      "     0     0 4081298.60    0   81 5027784.00 4081298.60  18.8%     -    0s\n",
      "     0     0 4081471.17    0   78 5027784.00 4081471.17  18.8%     -    0s\n",
      "H    0     0                    4833271.0000 4128023.87  14.6%     -    0s\n",
      "H    0     0                    4452158.0000 4128023.87  7.28%     -    0s\n",
      "H    0     0                    4431398.0000 4128023.87  6.85%     -    0s\n",
      "H    0     0                    4389258.0000 4128023.87  5.95%     -    0s\n",
      "     0     0 4128023.87    0   83 4389258.00 4128023.87  5.95%     -    0s\n",
      "     0     0 4131604.76    0   63 4389258.00 4131604.76  5.87%     -    0s\n",
      "     0     0 4134423.54    0   67 4389258.00 4134423.54  5.81%     -    0s\n",
      "     0     0 4134602.44    0   84 4389258.00 4134602.44  5.80%     -    0s\n",
      "     0     0 4141987.47    0  102 4389258.00 4141987.47  5.63%     -    0s\n",
      "H    0     0                    4381050.0000 4141987.47  5.46%     -    0s\n",
      "     0     0 4149713.44    0  102 4381050.00 4149713.44  5.28%     -    0s\n",
      "     0     0 4149758.23    0   79 4381050.00 4149758.23  5.28%     -    0s\n",
      "     0     0 4156615.55    0  113 4381050.00 4156615.55  5.12%     -    0s\n",
      "     0     0 4161177.38    0  115 4381050.00 4161177.38  5.02%     -    0s\n",
      "     0     0 4161619.14    0  117 4381050.00 4161619.14  5.01%     -    0s\n",
      "     0     0 4164934.12    0  100 4381050.00 4164934.12  4.93%     -    0s\n",
      "     0     0 4165015.42    0  120 4381050.00 4165015.42  4.93%     -    0s\n",
      "     0     0 4171861.77    0  122 4381050.00 4171861.77  4.77%     -    0s\n",
      "     0     0 4178486.56    0  122 4381050.00 4178486.56  4.62%     -    0s\n",
      "H    0     0                    4328647.0000 4178486.56  3.47%     -    0s\n",
      "H    0     0                    4319363.0000 4178486.56  3.26%     -    0s\n",
      "     0     0 4178486.56    0   24 4319363.00 4178486.56  3.26%     -    0s\n",
      "     0     0 4178486.56    0   54 4319363.00 4178486.56  3.26%     -    0s\n",
      "     0     0 4178486.56    0   78 4319363.00 4178486.56  3.26%     -    0s\n",
      "     0     0 4178486.56    0   94 4319363.00 4178486.56  3.26%     -    0s\n",
      "     0     0 4178486.56    0   89 4319363.00 4178486.56  3.26%     -    0s\n",
      "     0     0 4178812.89    0  103 4319363.00 4178812.89  3.25%     -    0s\n",
      "     0     0 4181029.37    0  102 4319363.00 4181029.37  3.20%     -    0s\n",
      "     0     0 4187833.59    0  105 4319363.00 4187833.59  3.05%     -    0s\n",
      "     0     0 4189016.15    0  107 4319363.00 4189016.15  3.02%     -    0s\n",
      "     0     0 4189081.53    0  108 4319363.00 4189081.53  3.02%     -    0s\n",
      "     0     0 4192244.85    0  100 4319363.00 4192244.85  2.94%     -    0s\n",
      "     0     0 4192430.71    0   95 4319363.00 4192430.71  2.94%     -    0s\n",
      "     0     0 4192840.81    0  103 4319363.00 4192840.81  2.93%     -    0s\n",
      "     0     0 4193145.50    0  106 4319363.00 4193145.50  2.92%     -    0s\n",
      "     0     0 4193168.47    0  108 4319363.00 4193168.47  2.92%     -    0s\n",
      "     0     0 4195035.42    0   98 4319363.00 4195035.42  2.88%     -    0s\n",
      "     0     0 4195161.88    0  107 4319363.00 4195161.88  2.88%     -    0s\n",
      "     0     0 4195324.09    0  110 4319363.00 4195324.09  2.87%     -    0s\n",
      "     0     0 4196022.28    0  110 4319363.00 4196022.28  2.86%     -    0s\n",
      "H    0     0                    4309936.0000 4199602.06  2.56%     -    0s\n",
      "     0     2 4199602.06    0  110 4309936.00 4199602.06  2.56%     -    0s\n",
      "H   61    38                    4305904.0000 4233660.16  1.68%  16.1    0s\n",
      "H  221    38                    4298871.0000 4270761.24  0.65%  13.3    0s\n",
      "*  276    19              11    4292938.0000 4272120.57  0.48%  12.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 3\n",
      "  Cover: 34\n",
      "  MIR: 30\n",
      "  StrongCG: 13\n",
      "  RLT: 7\n",
      "\n",
      "Explored 336 nodes (4974 simplex iterations) in 0.35 seconds (0.12 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 4.29294e+06 4.29887e+06 4.3059e+06 ... 4.45216e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.292938000000e+06, best bound 4.292938000000e+06, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Optimize the model\n",
    "model.optimize()\n",
    "\n",
    "# model.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eebf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model output\n",
    "\n",
    "def print_full_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            print(f\"Y[{s},{v}] = {y[s,v]}\")\n",
    "\n",
    "def print_concise_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                if x[e,s,v].x:\n",
    "                    print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            if y[s,v].x:\n",
    "                print(f\"Y[{s},{v}] = {y[s,v]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a6825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization successful!\n",
      "Optimal X [endpoint, server, video] values:\n",
      "X[0,0,7] * 170 = <gurobi.Var x[0,0,7] (value 1.0)>\n",
      "X[0,0,31] * 170 = <gurobi.Var x[0,0,31] (value 1.0)>\n",
      "X[0,1,1] * 22 = <gurobi.Var x[0,1,1] (value 1.0)>\n",
      "X[0,1,15] * 22 = <gurobi.Var x[0,1,15] (value 1.0)>\n",
      "X[0,1,65] * 22 = <gurobi.Var x[0,1,65] (value 1.0)>\n",
      "X[0,1,99] * 22 = <gurobi.Var x[0,1,99] (value 1.0)>\n",
      "X[0,2,8] * 224 = <gurobi.Var x[0,2,8] (value 1.0)>\n",
      "X[0,2,13] * 224 = <gurobi.Var x[0,2,13] (value 1.0)>\n",
      "X[0,10,26] * 1013 = <gurobi.Var x[0,10,26] (value 1.0)>\n",
      "X[1,0,5] * 7 = <gurobi.Var x[1,0,5] (value 1.0)>\n",
      "X[1,0,7] * 7 = <gurobi.Var x[1,0,7] (value 1.0)>\n",
      "X[1,0,10] * 7 = <gurobi.Var x[1,0,10] (value 1.0)>\n",
      "X[1,0,46] * 7 = <gurobi.Var x[1,0,46] (value 1.0)>\n",
      "X[1,1,0] * 50 = <gurobi.Var x[1,1,0] (value 1.0)>\n",
      "X[1,1,1] * 50 = <gurobi.Var x[1,1,1] (value 1.0)>\n",
      "X[1,10,89] * 696 = <gurobi.Var x[1,10,89] (value 1.0)>\n",
      "X[2,4,8] * 175 = <gurobi.Var x[2,4,8] (value 1.0)>\n",
      "X[2,4,17] * 175 = <gurobi.Var x[2,4,17] (value 1.0)>\n",
      "X[2,4,81] * 175 = <gurobi.Var x[2,4,81] (value 1.0)>\n",
      "X[2,5,0] * 2 = <gurobi.Var x[2,5,0] (value 1.0)>\n",
      "X[2,5,7] * 2 = <gurobi.Var x[2,5,7] (value 1.0)>\n",
      "X[2,5,10] * 2 = <gurobi.Var x[2,5,10] (value 1.0)>\n",
      "X[2,5,13] * 2 = <gurobi.Var x[2,5,13] (value 1.0)>\n",
      "X[2,5,32] * 2 = <gurobi.Var x[2,5,32] (value 1.0)>\n",
      "X[2,10,3] * 1114 = <gurobi.Var x[2,10,3] (value 1.0)>\n",
      "X[3,1,0] * 24 = <gurobi.Var x[3,1,0] (value 1.0)>\n",
      "X[3,1,1] * 24 = <gurobi.Var x[3,1,1] (value 1.0)>\n",
      "X[3,1,10] * 24 = <gurobi.Var x[3,1,10] (value 1.0)>\n",
      "X[3,8,2] * 25 = <gurobi.Var x[3,8,2] (value 1.0)>\n",
      "X[3,8,3] * 25 = <gurobi.Var x[3,8,3] (value 1.0)>\n",
      "X[3,8,6] * 25 = <gurobi.Var x[3,8,6] (value 1.0)>\n",
      "X[3,8,16] * 25 = <gurobi.Var x[3,8,16] (value 1.0)>\n",
      "X[3,10,34] * 464 = <gurobi.Var x[3,10,34] (value 1.0)>\n",
      "X[4,3,8] * 216 = <gurobi.Var x[4,3,8] (value 1.0)>\n",
      "X[4,5,0] * 155 = <gurobi.Var x[4,5,0] (value 1.0)>\n",
      "X[4,6,27] * 139 = <gurobi.Var x[4,6,27] (value 1.0)>\n",
      "X[4,7,24] * 208 = <gurobi.Var x[4,7,24] (value 1.0)>\n",
      "X[4,7,54] * 208 = <gurobi.Var x[4,7,54] (value 1.0)>\n",
      "X[4,8,2] * 145 = <gurobi.Var x[4,8,2] (value 1.0)>\n",
      "X[4,8,3] * 145 = <gurobi.Var x[4,8,3] (value 1.0)>\n",
      "X[4,10,26] * 522 = <gurobi.Var x[4,10,26] (value 1.0)>\n",
      "X[5,0,5] * 26 = <gurobi.Var x[5,0,5] (value 1.0)>\n",
      "X[5,0,16] * 26 = <gurobi.Var x[5,0,16] (value 1.0)>\n",
      "X[5,2,8] * 70 = <gurobi.Var x[5,2,8] (value 1.0)>\n",
      "X[5,2,19] * 70 = <gurobi.Var x[5,2,19] (value 1.0)>\n",
      "X[5,8,2] * 159 = <gurobi.Var x[5,8,2] (value 1.0)>\n",
      "X[5,8,82] * 159 = <gurobi.Var x[5,8,82] (value 1.0)>\n",
      "X[5,9,1] * 92 = <gurobi.Var x[5,9,1] (value 1.0)>\n",
      "X[6,2,4] * 163 = <gurobi.Var x[6,2,4] (value 1.0)>\n",
      "X[6,2,8] * 163 = <gurobi.Var x[6,2,8] (value 1.0)>\n",
      "X[6,2,16] * 163 = <gurobi.Var x[6,2,16] (value 1.0)>\n",
      "X[6,9,0] * 153 = <gurobi.Var x[6,9,0] (value 1.0)>\n",
      "X[6,9,1] * 153 = <gurobi.Var x[6,9,1] (value 1.0)>\n",
      "X[6,9,23] * 153 = <gurobi.Var x[6,9,23] (value 1.0)>\n",
      "X[6,9,43] * 153 = <gurobi.Var x[6,9,43] (value 1.0)>\n",
      "X[6,10,62] * 1288 = <gurobi.Var x[6,10,62] (value 1.0)>\n",
      "X[7,7,1] * 86 = <gurobi.Var x[7,7,1] (value 1.0)>\n",
      "X[7,7,5] * 86 = <gurobi.Var x[7,7,5] (value 1.0)>\n",
      "X[7,7,54] * 86 = <gurobi.Var x[7,7,54] (value 1.0)>\n",
      "X[7,7,74] * 86 = <gurobi.Var x[7,7,74] (value 1.0)>\n",
      "X[7,10,2] * 226 = <gurobi.Var x[7,10,2] (value 1.0)>\n",
      "X[7,10,7] * 226 = <gurobi.Var x[7,10,7] (value 1.0)>\n",
      "X[7,10,11] * 226 = <gurobi.Var x[7,10,11] (value 1.0)>\n",
      "X[7,10,65] * 226 = <gurobi.Var x[7,10,65] (value 1.0)>\n",
      "X[8,5,0] * 79 = <gurobi.Var x[8,5,0] (value 1.0)>\n",
      "X[8,5,13] * 79 = <gurobi.Var x[8,5,13] (value 1.0)>\n",
      "X[8,6,4] * 9 = <gurobi.Var x[8,6,4] (value 1.0)>\n",
      "X[8,6,16] * 9 = <gurobi.Var x[8,6,16] (value 1.0)>\n",
      "X[8,6,21] * 9 = <gurobi.Var x[8,6,21] (value 1.0)>\n",
      "X[8,6,30] * 9 = <gurobi.Var x[8,6,30] (value 1.0)>\n",
      "X[8,7,1] * 53 = <gurobi.Var x[8,7,1] (value 1.0)>\n",
      "X[8,8,3] * 67 = <gurobi.Var x[8,8,3] (value 1.0)>\n",
      "X[8,10,44] * 316 = <gurobi.Var x[8,10,44] (value 1.0)>\n",
      "X[9,3,4] * 62 = <gurobi.Var x[9,3,4] (value 1.0)>\n",
      "X[9,3,5] * 62 = <gurobi.Var x[9,3,5] (value 1.0)>\n",
      "X[9,3,10] * 62 = <gurobi.Var x[9,3,10] (value 1.0)>\n",
      "X[9,3,16] * 62 = <gurobi.Var x[9,3,16] (value 1.0)>\n",
      "X[9,3,30] * 62 = <gurobi.Var x[9,3,30] (value 1.0)>\n",
      "X[9,9,0] * 66 = <gurobi.Var x[9,9,0] (value 1.0)>\n",
      "X[9,9,1] * 66 = <gurobi.Var x[9,9,1] (value 1.0)>\n",
      "X[9,10,2] * 365 = <gurobi.Var x[9,10,2] (value 1.0)>\n",
      "\n",
      "Optimal Y [server, video] values:\n",
      "Y[0,5] = <gurobi.Var y[0,5] (value 1.0)>\n",
      "Y[0,7] = <gurobi.Var y[0,7] (value 1.0)>\n",
      "Y[0,10] = <gurobi.Var y[0,10] (value 1.0)>\n",
      "Y[0,16] = <gurobi.Var y[0,16] (value 1.0)>\n",
      "Y[0,31] = <gurobi.Var y[0,31] (value 1.0)>\n",
      "Y[0,46] = <gurobi.Var y[0,46] (value 1.0)>\n",
      "Y[1,0] = <gurobi.Var y[1,0] (value 1.0)>\n",
      "Y[1,1] = <gurobi.Var y[1,1] (value 1.0)>\n",
      "Y[1,10] = <gurobi.Var y[1,10] (value 1.0)>\n",
      "Y[1,15] = <gurobi.Var y[1,15] (value 1.0)>\n",
      "Y[1,65] = <gurobi.Var y[1,65] (value 1.0)>\n",
      "Y[1,99] = <gurobi.Var y[1,99] (value 1.0)>\n",
      "Y[2,4] = <gurobi.Var y[2,4] (value 1.0)>\n",
      "Y[2,8] = <gurobi.Var y[2,8] (value 1.0)>\n",
      "Y[2,13] = <gurobi.Var y[2,13] (value 1.0)>\n",
      "Y[2,16] = <gurobi.Var y[2,16] (value 1.0)>\n",
      "Y[2,19] = <gurobi.Var y[2,19] (value 1.0)>\n",
      "Y[3,4] = <gurobi.Var y[3,4] (value 1.0)>\n",
      "Y[3,5] = <gurobi.Var y[3,5] (value 1.0)>\n",
      "Y[3,8] = <gurobi.Var y[3,8] (value 1.0)>\n",
      "Y[3,10] = <gurobi.Var y[3,10] (value 1.0)>\n",
      "Y[3,16] = <gurobi.Var y[3,16] (value 1.0)>\n",
      "Y[3,30] = <gurobi.Var y[3,30] (value 1.0)>\n",
      "Y[4,8] = <gurobi.Var y[4,8] (value 1.0)>\n",
      "Y[4,17] = <gurobi.Var y[4,17] (value 1.0)>\n",
      "Y[4,81] = <gurobi.Var y[4,81] (value 1.0)>\n",
      "Y[5,0] = <gurobi.Var y[5,0] (value 1.0)>\n",
      "Y[5,7] = <gurobi.Var y[5,7] (value 1.0)>\n",
      "Y[5,10] = <gurobi.Var y[5,10] (value 1.0)>\n",
      "Y[5,13] = <gurobi.Var y[5,13] (value 1.0)>\n",
      "Y[5,32] = <gurobi.Var y[5,32] (value 1.0)>\n",
      "Y[6,4] = <gurobi.Var y[6,4] (value 1.0)>\n",
      "Y[6,16] = <gurobi.Var y[6,16] (value 1.0)>\n",
      "Y[6,21] = <gurobi.Var y[6,21] (value 1.0)>\n",
      "Y[6,27] = <gurobi.Var y[6,27] (value 1.0)>\n",
      "Y[6,30] = <gurobi.Var y[6,30] (value 1.0)>\n",
      "Y[7,1] = <gurobi.Var y[7,1] (value 1.0)>\n",
      "Y[7,5] = <gurobi.Var y[7,5] (value 1.0)>\n",
      "Y[7,24] = <gurobi.Var y[7,24] (value 1.0)>\n",
      "Y[7,54] = <gurobi.Var y[7,54] (value 1.0)>\n",
      "Y[7,74] = <gurobi.Var y[7,74] (value 1.0)>\n",
      "Y[8,2] = <gurobi.Var y[8,2] (value 1.0)>\n",
      "Y[8,3] = <gurobi.Var y[8,3] (value 1.0)>\n",
      "Y[8,6] = <gurobi.Var y[8,6] (value 1.0)>\n",
      "Y[8,16] = <gurobi.Var y[8,16] (value 1.0)>\n",
      "Y[8,82] = <gurobi.Var y[8,82] (value 1.0)>\n",
      "Y[9,0] = <gurobi.Var y[9,0] (value 1.0)>\n",
      "Y[9,1] = <gurobi.Var y[9,1] (value 1.0)>\n",
      "Y[9,23] = <gurobi.Var y[9,23] (value 1.0)>\n",
      "Y[9,43] = <gurobi.Var y[9,43] (value 1.0)>\n",
      "Y[10,0] = <gurobi.Var y[10,0] (value 1.0)>\n",
      "Y[10,1] = <gurobi.Var y[10,1] (value 1.0)>\n",
      "Y[10,2] = <gurobi.Var y[10,2] (value 1.0)>\n",
      "Y[10,3] = <gurobi.Var y[10,3] (value 1.0)>\n",
      "Y[10,4] = <gurobi.Var y[10,4] (value 1.0)>\n",
      "Y[10,5] = <gurobi.Var y[10,5] (value 1.0)>\n",
      "Y[10,6] = <gurobi.Var y[10,6] (value 1.0)>\n",
      "Y[10,7] = <gurobi.Var y[10,7] (value 1.0)>\n",
      "Y[10,8] = <gurobi.Var y[10,8] (value 1.0)>\n",
      "Y[10,9] = <gurobi.Var y[10,9] (value 1.0)>\n",
      "Y[10,10] = <gurobi.Var y[10,10] (value 1.0)>\n",
      "Y[10,11] = <gurobi.Var y[10,11] (value 1.0)>\n",
      "Y[10,12] = <gurobi.Var y[10,12] (value 1.0)>\n",
      "Y[10,13] = <gurobi.Var y[10,13] (value 1.0)>\n",
      "Y[10,14] = <gurobi.Var y[10,14] (value 1.0)>\n",
      "Y[10,15] = <gurobi.Var y[10,15] (value 1.0)>\n",
      "Y[10,16] = <gurobi.Var y[10,16] (value 1.0)>\n",
      "Y[10,17] = <gurobi.Var y[10,17] (value 1.0)>\n",
      "Y[10,18] = <gurobi.Var y[10,18] (value 1.0)>\n",
      "Y[10,19] = <gurobi.Var y[10,19] (value 1.0)>\n",
      "Y[10,20] = <gurobi.Var y[10,20] (value 1.0)>\n",
      "Y[10,21] = <gurobi.Var y[10,21] (value 1.0)>\n",
      "Y[10,22] = <gurobi.Var y[10,22] (value 1.0)>\n",
      "Y[10,23] = <gurobi.Var y[10,23] (value 1.0)>\n",
      "Y[10,24] = <gurobi.Var y[10,24] (value 1.0)>\n",
      "Y[10,25] = <gurobi.Var y[10,25] (value 1.0)>\n",
      "Y[10,26] = <gurobi.Var y[10,26] (value 1.0)>\n",
      "Y[10,27] = <gurobi.Var y[10,27] (value 1.0)>\n",
      "Y[10,28] = <gurobi.Var y[10,28] (value 1.0)>\n",
      "Y[10,29] = <gurobi.Var y[10,29] (value 1.0)>\n",
      "Y[10,30] = <gurobi.Var y[10,30] (value 1.0)>\n",
      "Y[10,31] = <gurobi.Var y[10,31] (value 1.0)>\n",
      "Y[10,32] = <gurobi.Var y[10,32] (value 1.0)>\n",
      "Y[10,33] = <gurobi.Var y[10,33] (value 1.0)>\n",
      "Y[10,34] = <gurobi.Var y[10,34] (value 1.0)>\n",
      "Y[10,35] = <gurobi.Var y[10,35] (value 1.0)>\n",
      "Y[10,36] = <gurobi.Var y[10,36] (value 1.0)>\n",
      "Y[10,37] = <gurobi.Var y[10,37] (value 1.0)>\n",
      "Y[10,38] = <gurobi.Var y[10,38] (value 1.0)>\n",
      "Y[10,39] = <gurobi.Var y[10,39] (value 1.0)>\n",
      "Y[10,40] = <gurobi.Var y[10,40] (value 1.0)>\n",
      "Y[10,41] = <gurobi.Var y[10,41] (value 1.0)>\n",
      "Y[10,42] = <gurobi.Var y[10,42] (value 1.0)>\n",
      "Y[10,43] = <gurobi.Var y[10,43] (value 1.0)>\n",
      "Y[10,44] = <gurobi.Var y[10,44] (value 1.0)>\n",
      "Y[10,45] = <gurobi.Var y[10,45] (value 1.0)>\n",
      "Y[10,46] = <gurobi.Var y[10,46] (value 1.0)>\n",
      "Y[10,47] = <gurobi.Var y[10,47] (value 1.0)>\n",
      "Y[10,48] = <gurobi.Var y[10,48] (value 1.0)>\n",
      "Y[10,49] = <gurobi.Var y[10,49] (value 1.0)>\n",
      "Y[10,50] = <gurobi.Var y[10,50] (value 1.0)>\n",
      "Y[10,51] = <gurobi.Var y[10,51] (value 1.0)>\n",
      "Y[10,52] = <gurobi.Var y[10,52] (value 1.0)>\n",
      "Y[10,53] = <gurobi.Var y[10,53] (value 1.0)>\n",
      "Y[10,54] = <gurobi.Var y[10,54] (value 1.0)>\n",
      "Y[10,55] = <gurobi.Var y[10,55] (value 1.0)>\n",
      "Y[10,56] = <gurobi.Var y[10,56] (value 1.0)>\n",
      "Y[10,57] = <gurobi.Var y[10,57] (value 1.0)>\n",
      "Y[10,58] = <gurobi.Var y[10,58] (value 1.0)>\n",
      "Y[10,59] = <gurobi.Var y[10,59] (value 1.0)>\n",
      "Y[10,60] = <gurobi.Var y[10,60] (value 1.0)>\n",
      "Y[10,61] = <gurobi.Var y[10,61] (value 1.0)>\n",
      "Y[10,62] = <gurobi.Var y[10,62] (value 1.0)>\n",
      "Y[10,63] = <gurobi.Var y[10,63] (value 1.0)>\n",
      "Y[10,64] = <gurobi.Var y[10,64] (value 1.0)>\n",
      "Y[10,65] = <gurobi.Var y[10,65] (value 1.0)>\n",
      "Y[10,66] = <gurobi.Var y[10,66] (value 1.0)>\n",
      "Y[10,67] = <gurobi.Var y[10,67] (value 1.0)>\n",
      "Y[10,68] = <gurobi.Var y[10,68] (value 1.0)>\n",
      "Y[10,69] = <gurobi.Var y[10,69] (value 1.0)>\n",
      "Y[10,70] = <gurobi.Var y[10,70] (value 1.0)>\n",
      "Y[10,71] = <gurobi.Var y[10,71] (value 1.0)>\n",
      "Y[10,72] = <gurobi.Var y[10,72] (value 1.0)>\n",
      "Y[10,73] = <gurobi.Var y[10,73] (value 1.0)>\n",
      "Y[10,74] = <gurobi.Var y[10,74] (value 1.0)>\n",
      "Y[10,75] = <gurobi.Var y[10,75] (value 1.0)>\n",
      "Y[10,76] = <gurobi.Var y[10,76] (value 1.0)>\n",
      "Y[10,77] = <gurobi.Var y[10,77] (value 1.0)>\n",
      "Y[10,78] = <gurobi.Var y[10,78] (value 1.0)>\n",
      "Y[10,79] = <gurobi.Var y[10,79] (value 1.0)>\n",
      "Y[10,80] = <gurobi.Var y[10,80] (value 1.0)>\n",
      "Y[10,81] = <gurobi.Var y[10,81] (value 1.0)>\n",
      "Y[10,82] = <gurobi.Var y[10,82] (value 1.0)>\n",
      "Y[10,83] = <gurobi.Var y[10,83] (value 1.0)>\n",
      "Y[10,84] = <gurobi.Var y[10,84] (value 1.0)>\n",
      "Y[10,85] = <gurobi.Var y[10,85] (value 1.0)>\n",
      "Y[10,86] = <gurobi.Var y[10,86] (value 1.0)>\n",
      "Y[10,87] = <gurobi.Var y[10,87] (value 1.0)>\n",
      "Y[10,88] = <gurobi.Var y[10,88] (value 1.0)>\n",
      "Y[10,89] = <gurobi.Var y[10,89] (value 1.0)>\n",
      "Y[10,90] = <gurobi.Var y[10,90] (value 1.0)>\n",
      "Y[10,91] = <gurobi.Var y[10,91] (value 1.0)>\n",
      "Y[10,92] = <gurobi.Var y[10,92] (value 1.0)>\n",
      "Y[10,93] = <gurobi.Var y[10,93] (value 1.0)>\n",
      "Y[10,94] = <gurobi.Var y[10,94] (value 1.0)>\n",
      "Y[10,95] = <gurobi.Var y[10,95] (value 1.0)>\n",
      "Y[10,96] = <gurobi.Var y[10,96] (value 1.0)>\n",
      "Y[10,97] = <gurobi.Var y[10,97] (value 1.0)>\n",
      "Y[10,98] = <gurobi.Var y[10,98] (value 1.0)>\n",
      "Y[10,99] = <gurobi.Var y[10,99] (value 1.0)>\n",
      "\n",
      "Optimal objective value: 4292938.0\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "if model.status == gp.GRB.OPTIMAL:\n",
    "    print(\"\\nOptimization successful!\")\n",
    "    # print_full_output()\n",
    "    print_concise_output()\n",
    "    print(f\"\\nOptimal objective value: {model.objVal}\")\n",
    "    OPTIMAL_SOLUTION = model.ObjVal\n",
    "elif model.status == gp.GRB.INFEASIBLE:\n",
    "    print(\"Model is infeasible.\")\n",
    "elif model.status == gp.GRB.UNBOUNDED:\n",
    "    print(\"Model is unbounded.\")\n",
    "else:\n",
    "    print(f\"Optimization ended with status {model.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13b29c",
   "metadata": {},
   "source": [
    "---\n",
    "# heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c355ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common\n",
    "def compute_obj_func(x):\n",
    "    return sum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "\n",
    "x_sol = []\n",
    "y_sol = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09de88",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d547ffa",
   "metadata": {},
   "source": [
    "### 1. place video with highest request number in nearest cache when possible and place all videos for the endpoint in the order that we get\n",
    "order video by request number, and for every endpoint retrieven from this ordered list place all its requested videos in best available caches for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039aa21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6347627.0 - GAP: 47.86207021857758% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs.extend((e, v) for v in sorted_vs)\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) \n",
    "y = np.zeros(((num_server+1), num_video)) \n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req in sorted_reqs:\n",
    "    req_endpoint = req[E_IND]\n",
    "    req_video = req[V_IND]\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append(x)\n",
    "y_sol.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9e886",
   "metadata": {},
   "source": [
    "### 2. place video with highest request number in nearest cache + round robin (every iteration change endpoint)\n",
    "order video by request number, use a round robin schedulo to choose an endpoint retrieven from this ordered list and place its remaining requested video in best available cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0775a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 7091338.0 - GAP: 65.18612661072673% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = defaultdict(list)\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs[e] = sorted_vs\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "Done = False\n",
    "endpoints_req_index = [0 for _ in server_index]\n",
    "while not Done:\n",
    "    Done = True\n",
    "    for curr_endpoint in endpoint_index:\n",
    "        curr_endpoint_req_index = endpoints_req_index[curr_endpoint]\n",
    "        \n",
    "        if curr_endpoint_req_index < len(sorted_reqs[curr_endpoint]):\n",
    "            Done = False # There could still be reqs not satisfied other than this\n",
    "            req_video = sorted_reqs[curr_endpoint][curr_endpoint_req_index]\n",
    "            req_video_size = video_size[req_video]\n",
    "\n",
    "            for curr_cache_index in sorted_latency[curr_endpoint]:\n",
    "                if y[curr_cache_index, req_video]:\n",
    "                    x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                        curr_capacity[curr_cache_index] -= req_video_size\n",
    "                        y[curr_cache_index, req_video] = 1\n",
    "                        x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                        break\n",
    "                    \n",
    "        endpoints_req_index[curr_endpoint] += 1\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append(x)\n",
    "y_sol.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87489dbd",
   "metadata": {},
   "source": [
    "### 3. place video with highest request number in nearest cache when possible\n",
    "(only order by request number without considering the endpoints, pratically place cache video in the best server order by request number withouth reasoning on endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e34ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6776093.0 - GAP: 57.842787387099456% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "sorted_reqs = sorted(\n",
    "    [(e, v) for e in range(len(reqs)) for v in reqs[e] if reqs[e][v] != 0],\n",
    "    key=lambda pair: reqs[pair[0]][pair[1]],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req_endpoint,req_video in sorted_reqs:\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append(x)\n",
    "y_sol.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dd1d5",
   "metadata": {},
   "source": [
    "### 4. Place video ordered by popularity in cache with most connected endpoints for that video\n",
    "Order video by request number and place ordered video in the cache connected with most endpoints that have requested that specific video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aa52075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9816241.0 - GAP: 128.66020892917624% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "video_req_count = [0 for _ in video_index]\n",
    "latency_sum = defaultdict(lambda: defaultdict(lambda: defaultdict(int))) # used to find best cache to place a video [server][video][latency sum / num endpoint / score]\n",
    "LATENCY_INDEX = 0\n",
    "NUM_ENDPOINT_CONNECTED_INDEX = 1\n",
    "SCORE_INDEX = 2\n",
    "\n",
    "for curr_endpoint_index, endpoint_reqs in reqs.items():\n",
    "    for curr_video_index, req_num in endpoint_reqs.items():\n",
    "        if req_num: # check if requests from endpoint for the video exists\n",
    "            video_req_count[curr_video_index] += req_num\n",
    "            for curr_server_index, lat in latency[curr_endpoint_index].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    latency_sum[curr_server_index][curr_video_index][LATENCY_INDEX] += lat\n",
    "                    latency_sum[curr_server_index][curr_video_index][NUM_ENDPOINT_CONNECTED_INDEX] += 1\n",
    "                    latency_sum[curr_server_index][curr_video_index][SCORE_INDEX] = (\n",
    "                        latency_sum[curr_server_index][curr_video_index][NUM_ENDPOINT_CONNECTED_INDEX] \n",
    "                        /\n",
    "                        latency_sum[curr_server_index][curr_video_index][LATENCY_INDEX]\n",
    "                    )\n",
    "            \n",
    "sorted_video_indexes = sorted(range(num_video), key=lambda i: video_req_count[i], reverse=True)\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "# print(curr_capacity)\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    # Sort v indices by ascending value for this e\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "for curr_video_index in sorted_video_indexes:\n",
    "    # now sort caches to get the ones with most connected endpoints that have requested video curr_video_index\n",
    "    for curr_server_index in sorted(\n",
    "        [\n",
    "            i\n",
    "            for i in range(len(latency_sum))\n",
    "            if latency_sum[i][curr_video_index][NUM_ENDPOINT_CONNECTED_INDEX] != 0\n",
    "        ],\n",
    "        key=lambda i: latency_sum[i][curr_video_index][NUM_ENDPOINT_CONNECTED_INDEX],\n",
    "        reverse=True\n",
    "    ):\n",
    "        if not y[curr_server_index, curr_video_index]:\n",
    "            if curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "                curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "                y[curr_server_index, curr_video_index] = 1\n",
    "                break\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append(x)\n",
    "y_sol.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66908d",
   "metadata": {},
   "source": [
    "### 5. place video based on connected endpoint most requested videos\n",
    "for every caches, place their most requested video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702ccb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9519517.0 - GAP: 121.74829918344965% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "sorted_reqs = sorted(\n",
    "    [(e, v) for e in range(len(reqs)) for v in reqs[e] if reqs[e][v] != 0],\n",
    "    key=lambda pair: reqs[pair[0]][pair[1]],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "\n",
    "# get total possible reqs for any cache server from its connected endpoints\n",
    "server_total_reqs = defaultdict(lambda: defaultdict(int))\n",
    "for req_endpoint,req_videos in reqs.items():\n",
    "    for curr_server_index, lat in latency[req_endpoint].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    for curr_video_index in req_videos.keys():\n",
    "                        server_total_reqs[curr_server_index][curr_video_index] += req_videos[curr_video_index]\n",
    "\n",
    "\n",
    "# place video in caches based on request counts\n",
    "for curr_server_index in server_index[:-1]:\n",
    "    sorted_indexes_only = [\n",
    "        video_index\n",
    "        for video_index, count in sorted(\n",
    "            server_total_reqs[curr_server_index].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        if count > 0\n",
    "    ]\n",
    "    for curr_video_index in sorted_indexes_only:\n",
    "        if not y[curr_server_index, curr_video_index] and curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "            curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "            y[curr_server_index, curr_video_index] = 1\n",
    "\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append(x)\n",
    "y_sol.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63615d",
   "metadata": {},
   "source": [
    "## Local Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0c175",
   "metadata": {},
   "source": [
    "### tabu search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7ff2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_x(y):\n",
    "    x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "\n",
    "    # Sort server s latency for endpoint e\n",
    "    sorted_latency = defaultdict(list)\n",
    "    for e in latency:\n",
    "        sorted_s = sorted(\n",
    "            [s for s in latency[e] if latency[e][s] != 0],\n",
    "            key=lambda s: latency[e][s]\n",
    "        )\n",
    "        sorted_latency[e] = sorted_s\n",
    "    \n",
    "    for curr_endpoint_index in endpoint_index:\n",
    "        for curr_video_index in reqs[curr_endpoint_index]:\n",
    "            best_server_index = num_server  # default to datacenter\n",
    "            \n",
    "            for curr_server_index in sorted_latency[curr_endpoint_index]:                    \n",
    "                if y[curr_server_index][curr_video_index]:\n",
    "                    best_server_index = curr_server_index\n",
    "                    break\n",
    "\n",
    "            x[curr_endpoint_index][best_server_index][curr_video_index] = 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5369a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_toggle(x, y, num_iters=1000, tabu_tenure=10):\n",
    "    tabu_list = deque(maxlen=tabu_tenure)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "\n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                if move in tabu_list and obj_val >= best_obj_val:\n",
    "                    continue\n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                new_y[curr_server_index][curr_video_index] = 1 - new_y[curr_server_index][curr_video_index]\n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "\n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # Random intensification\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "136e156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_add(x, y, num_iters=1000, tabu_tenure=10):\n",
    "    tabu_list = deque(maxlen=tabu_tenure)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "\n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                if move in tabu_list and obj_val >= best_obj_val:\n",
    "                    continue\n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                \n",
    "                # Try adding current video in current server if not already present\n",
    "                if new_y[curr_server_index][curr_video_index]:\n",
    "                    continue\n",
    "                new_y[curr_server_index][curr_video_index] = 1 \n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "\n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # Random intensification\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24d4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old solution: 6776093.0, tabu sol: 6776093.0, best sol 4292938.0\n",
      "old solution: 6776093.0, tabu sol: 6776093.0, best sol 4292938.0\n",
      "old solution: 9816241.0, tabu sol: 7161592.0, best sol 4292938.0\n",
      "old solution: 9816241.0, tabu sol: 7275848.0, best sol 4292938.0\n"
     ]
    }
   ],
   "source": [
    "for sol_index in [2,3]:\n",
    "    x_tabu, y_tabu, delay_tabu = tabu_search_toggle(x_sol[sol_index], y_sol[sol_index])\n",
    "    print(f\"old solution: {compute_obj_func(x_sol[sol_index])}, tabu sol: {delay_tabu}, best sol {OPTIMAL_SOLUTION}\")\n",
    "    x_tabu, y_tabu, delay_tabu = tabu_search_add(x_sol[sol_index], y_sol[sol_index])\n",
    "    print(f\"old solution: {compute_obj_func(x_sol[sol_index])}, tabu sol: {delay_tabu}, best sol {OPTIMAL_SOLUTION}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7701ef4",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
