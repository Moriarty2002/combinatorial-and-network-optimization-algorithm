{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9903b1c7",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b967f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b59b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMAL_SOLUTION = 0 # used to evaluate gap between math model and heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28210e55",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6217fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_video = 0\n",
    "num_endpoint = 0\n",
    "num_req_descriptions = 0\n",
    "num_server = 0\n",
    "\n",
    "cache_capacity = 0\n",
    "video_size = []\n",
    "\n",
    "latency = defaultdict(lambda: defaultdict(int))     # [endpoint][cache/datacenter] = latency\n",
    "reqs = defaultdict(lambda: defaultdict(int))        # [endpoint][video] = num reqs\n",
    "\n",
    "# dataset = \"dataset/videos_worth_spreading.in\"\n",
    "dataset = \"dataset/me_at_the_zoo.in\"\n",
    "# dataset = \"dataset/custom.in\"\n",
    "# dataset = \"dataset/minimal.in\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85803ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 0\n",
    "curr_endpoint_index = 0\n",
    "num_connected_cache = 0\n",
    "with open(dataset, \"r\") as f:\n",
    "    for line_content in f:\n",
    "        line = line_content.split()\n",
    "\n",
    "        if status ==0:                                  # get counters\n",
    "            num_video = int(line[0])\n",
    "            num_endpoint = int(line[1])\n",
    "            num_req_descriptions = int(line[2])\n",
    "            num_server = int(line[3])\n",
    "            cache_capacity = int(line[4])\n",
    "            status = 1\n",
    "\n",
    "        elif status == 1:                               # get video dims\n",
    "            for size in line:\n",
    "                video_size.append(int(size))\n",
    "            status = 2\n",
    "\n",
    "        elif status == 2:                               # get datacenter latency and connected cache number\n",
    "            data_center_latency = int(line[0])\n",
    "            latency[curr_endpoint_index][num_server] = data_center_latency\n",
    "            \n",
    "            num_connected_cache = int(line[1])\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "            else:\n",
    "                status = 3\n",
    "        \n",
    "        elif status == 3:                                  # get cache latency\n",
    "            cache_index = int(line[0])\n",
    "            cache_latency = int(line[1])\n",
    "            latency[curr_endpoint_index][cache_index] = cache_latency\n",
    "            \n",
    "            num_connected_cache = num_connected_cache - 1\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "                else:\n",
    "                    status = 2\n",
    "        \n",
    "        elif status == 4:                                   # take num requests\n",
    "            video_index = int(line[0])\n",
    "            curr_endpoint_index = int(line[1])\n",
    "            num_reqs = int(line[2])\n",
    "            reqs[curr_endpoint_index][video_index] = num_reqs                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fb2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common indexes\n",
    "endpoint_index = range(num_endpoint)\n",
    "server_index = range(num_server + 1) # I've modelled datacenter as last server\n",
    "video_index = range(num_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861cb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num video: 100, num endpoints 10, req descriptions 100, num cache 10, dim 100\n",
      "video sized: [20, 11, 50, 26, 5, 3, 6, 32, 40, 22, 4, 20, 50, 27, 49, 44, 1, 37, 35, 27, 14, 33, 6, 22, 23, 48, 44, 14, 26, 9, 46, 44, 15, 32, 31, 8, 39, 27, 39, 27, 1, 17, 1, 47, 44, 42, 16, 3, 44, 48, 5, 25, 4, 39, 39, 7, 24, 28, 14, 44, 22, 11, 27, 37, 11, 16, 50, 33, 22, 26, 7, 12, 17, 30, 12, 12, 4, 32, 12, 46, 43, 4, 12, 34, 11, 7, 47, 29, 24, 40, 41, 10, 5, 22, 22, 24, 37, 34, 50, 5]\n",
      "latencies: defaultdict(<function <lambda> at 0x7f732ca8dee0>, {0: defaultdict(<class 'int'>, {10: 1013, 0: 170, 1: 22, 2: 224}), 1: defaultdict(<class 'int'>, {10: 696, 0: 7, 1: 50}), 2: defaultdict(<class 'int'>, {10: 1114, 1: 202, 4: 175, 5: 2}), 3: defaultdict(<class 'int'>, {10: 464, 1: 24, 8: 25}), 4: defaultdict(<class 'int'>, {10: 522, 3: 216, 5: 155, 6: 139, 7: 208, 8: 145}), 5: defaultdict(<class 'int'>, {10: 321, 0: 26, 2: 70, 8: 159, 9: 92}), 6: defaultdict(<class 'int'>, {10: 1288, 2: 163, 9: 153}), 7: defaultdict(<class 'int'>, {10: 226, 7: 86}), 8: defaultdict(<class 'int'>, {10: 316, 4: 236, 5: 79, 6: 9, 7: 53, 8: 67}), 9: defaultdict(<class 'int'>, {10: 365, 2: 225, 3: 62, 5: 141, 6: 147, 9: 66})})\n",
      "reqs: defaultdict(<function <lambda> at 0x7f732ca8de40>, {4: defaultdict(<class 'int'>, {27: 340, 24: 279, 8: 862, 3: 214, 0: 306, 2: 906, 26: 10, 54: 621}), 8: defaultdict(<class 'int'>, {13: 249, 0: 865, 3: 247, 21: 880, 1: 211, 16: 93, 30: 882, 44: 267, 4: 859}), 1: defaultdict(<class 'int'>, {1: 449, 89: 297, 0: 930, 7: 116, 5: 554, 10: 128, 46: 435}), 2: defaultdict(<class 'int'>, {0: 817, 7: 785, 81: 120, 32: 717, 8: 396, 13: 934, 17: 605, 3: 103, 10: 709}), 5: defaultdict(<class 'int'>, {1: 51, 8: 935, 19: 748, 2: 853, 5: 676, 16: 620, 82: 720}), 9: defaultdict(<class 'int'>, {0: 580, 30: 927, 16: 996, 4: 266, 2: 179, 10: 280, 5: 537, 1: 116}), 3: defaultdict(<class 'int'>, {2: 986, 34: 752, 0: 865, 3: 899, 6: 577, 16: 70, 10: 849, 1: 409}), 0: defaultdict(<class 'int'>, {31: 585, 8: 186, 13: 459, 7: 214, 99: 772, 1: 884, 15: 737, 26: 194, 65: 926}), 6: defaultdict(<class 'int'>, {8: 300, 1: 988, 62: 8, 16: 939, 0: 400, 23: 262, 4: 512, 43: 331}), 7: defaultdict(<class 'int'>, {7: 204, 1: 228, 2: 861, 74: 885, 65: 109, 5: 314, 54: 671, 11: 301})})\n"
     ]
    }
   ],
   "source": [
    "print(f\"num video: {num_video}, num endpoints {num_endpoint}, req descriptions {num_req_descriptions}, num cache {num_server}, dim {cache_capacity}\")\n",
    "print(f\"video sized: {video_size}\")\n",
    "print(f\"latencies: {latency}\")\n",
    "print(f\"reqs: {reqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922188b",
   "metadata": {},
   "source": [
    "---\n",
    "# Math model for Guroby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac327f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2635449\n",
      "Academic license - for non-commercial use only - expires 2026-03-12\n",
      "Error: invalid user locale; possible fix is to set the system environment\n",
      "       variable 'LC_ALL' to a valid locale (e.g., to 'C')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 1: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 2: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 3: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 4: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 5: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 6: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 7: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 8: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 9: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 10: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 11: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 12: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 13: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 14: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 15: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 16: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 17: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 18: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 19: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 20: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 21: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 22: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 23: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 24: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 25: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 26: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 27: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 28: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 29: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 30: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 31: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 32: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 33: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 34: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 35: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 36: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 37: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 38: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 39: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 40: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 41: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 42: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 43: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 44: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 45: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 46: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 47: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 48: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 49: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 50: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 51: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 52: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 53: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 54: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 55: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 56: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 57: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 58: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 59: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 60: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 61: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 62: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 63: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 64: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 65: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 66: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 67: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 68: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 69: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 70: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 71: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 72: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 73: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 74: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 75: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 76: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 77: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 78: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 79: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 80: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 81: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 82: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 83: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 84: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 85: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 86: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 87: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 88: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 89: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 90: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 91: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 92: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 93: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 94: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 95: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 96: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 97: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 98: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 99: <gurobi.Constr *Awaiting Model Update*>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gp.Model(\"YoutubeCache\")\n",
    "\n",
    "# DECISION VARS\n",
    "x = model.addVars(endpoint_index, server_index, video_index, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "y = model.addVars(server_index, video_index, vtype=gp.GRB.BINARY, name=\"y\")\n",
    "\n",
    "# OBJECTIVE FUNCTION\n",
    "obj = gp.quicksum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "# the + y[s,v] it's used just to not let place useless video in cache server (but is not needed for this problem)\n",
    "# obj = gp.quicksum((latency[e][s]*reqs[e][v]*x[e,s,v] + y[s,v])for e in endpoint_index for s in server_index for v in video_index)\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "# CONSTRAINTS\n",
    "constr = (gp.quicksum(x[e,s,v] for e in endpoint_index)  <= num_endpoint*y[s,v] for s in server_index for v in video_index )\n",
    "model.addConstrs(constr, name=\"video v must be available on server s to be selected\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for v in video_index ) <= (num_video*latency[e][s]) for e in endpoint_index for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"endpoint can use only existing connection\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for s in server_index ) == (1 if reqs[e][v] else 0) for e in endpoint_index for v in video_index ) # datacenter excluded \n",
    "model.addConstrs(constr, name=\"every request must be satisfied\")\n",
    "\n",
    "constr = ( gp.quicksum(video_size[v] * y[s,v] for v in video_index) <= cache_capacity for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"cache capacity\")\n",
    "\n",
    "constr = ( y[num_server,v] == 1 for v in video_index ) # cache servers are from 0 to s-1, s index (num_server) is for datacenter\n",
    "model.addConstrs(constr, name=\"Datacenter have all videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d392c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (linux64 - \"Arch Linux\")\n",
      "\n",
      "CPU model: AMD Ryzen 7 5700U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 2310 rows, 12100 columns and 34200 nonzeros\n",
      "Model fingerprint: 0x8ed62ee6\n",
      "Variable types: 0 continuous, 12100 integer (12100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+01]\n",
      "  Objective range  [2e+02, 1e+06]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Found heuristic solution: objective 1.172420e+07\n",
      "Presolve removed 2169 rows and 11778 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 141 rows, 322 columns, 633 nonzeros\n",
      "Variable types: 0 continuous, 322 integer (322 binary)\n",
      "Found heuristic solution: objective 8551097.0000\n",
      "\n",
      "Root relaxation: objective 3.127974e+06, 126 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3127974.34    0   53 8551097.00 3127974.34  63.4%     -    0s\n",
      "H    0     0                    7118653.0000 3127974.34  56.1%     -    0s\n",
      "H    0     0                    7077316.0000 3127974.34  55.8%     -    0s\n",
      "H    0     0                    6340587.0000 3127974.34  50.7%     -    0s\n",
      "H    0     0                    6039143.0000 3127974.34  48.2%     -    0s\n",
      "H    0     0                    5702303.0000 3127974.34  45.1%     -    0s\n",
      "H    0     0                    5575476.0000 3127974.34  43.9%     -    0s\n",
      "H    0     0                    5437290.0000 3127974.34  42.5%     -    0s\n",
      "H    0     0                    5432136.0000 3745000.72  31.1%     -    0s\n",
      "H    0     0                    5362994.0000 3745000.72  30.2%     -    0s\n",
      "     0     0 3745000.72    0   55 5362994.00 3745000.72  30.2%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 4055513.01    0   59 5362994.00 4055513.01  24.4%     -    0s\n",
      "H    0     0                    5296306.0000 4062646.30  23.3%     -    0s\n",
      "H    0     0                    5292854.0000 4062646.30  23.2%     -    0s\n",
      "     0     0 4062646.30    0   53 5292854.00 4062646.30  23.2%     -    0s\n",
      "H    0     0                    5027784.0000 4078856.01  18.9%     -    0s\n",
      "     0     0 4078856.01    0   84 5027784.00 4078856.01  18.9%     -    0s\n",
      "     0     0 4081298.60    0   81 5027784.00 4081298.60  18.8%     -    0s\n",
      "     0     0 4081471.17    0   78 5027784.00 4081471.17  18.8%     -    0s\n",
      "H    0     0                    4833271.0000 4128023.87  14.6%     -    0s\n",
      "H    0     0                    4452158.0000 4128023.87  7.28%     -    0s\n",
      "H    0     0                    4431398.0000 4128023.87  6.85%     -    0s\n",
      "H    0     0                    4389258.0000 4128023.87  5.95%     -    0s\n",
      "     0     0 4128023.87    0   83 4389258.00 4128023.87  5.95%     -    0s\n",
      "     0     0 4131604.76    0   63 4389258.00 4131604.76  5.87%     -    0s\n",
      "     0     0 4134423.54    0   67 4389258.00 4134423.54  5.81%     -    0s\n",
      "     0     0 4134602.44    0   84 4389258.00 4134602.44  5.80%     -    0s\n",
      "     0     0 4141987.47    0  102 4389258.00 4141987.47  5.63%     -    0s\n",
      "     0     0 4149713.44    0  102 4389258.00 4149713.44  5.46%     -    0s\n",
      "     0     0 4149758.23    0   79 4389258.00 4149758.23  5.46%     -    0s\n",
      "     0     0 4156615.55    0  113 4389258.00 4156615.55  5.30%     -    0s\n",
      "     0     0 4161177.38    0  115 4389258.00 4161177.38  5.20%     -    0s\n",
      "     0     0 4161619.14    0  117 4389258.00 4161619.14  5.19%     -    0s\n",
      "     0     0 4164934.12    0  100 4389258.00 4164934.12  5.11%     -    0s\n",
      "     0     0 4165015.42    0  120 4389258.00 4165015.42  5.11%     -    0s\n",
      "     0     0 4171719.85    0  120 4389258.00 4171719.85  4.96%     -    0s\n",
      "     0     0 4177905.96    0  120 4389258.00 4177905.96  4.82%     -    0s\n",
      "H    0     0                    4381829.0000 4177905.96  4.65%     -    0s\n",
      "H    0     0                    4341105.0000 4177905.96  3.76%     -    0s\n",
      "H    0     0                    4329426.0000 4177905.96  3.50%     -    0s\n",
      "H    0     0                    4320142.0000 4177905.96  3.29%     -    0s\n",
      "     0     0 4177905.96    0   24 4320142.00 4177905.96  3.29%     -    0s\n",
      "H    0     0                    4309957.0000 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0   56 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0   84 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0  100 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177998.78    0   91 4309957.00 4177998.78  3.06%     -    0s\n",
      "     0     0 4178812.89    0  105 4309957.00 4178812.89  3.04%     -    0s\n",
      "     0     0 4181029.37    0  104 4309957.00 4181029.37  2.99%     -    0s\n",
      "     0     0 4188189.00    0  108 4309957.00 4188189.00  2.83%     -    0s\n",
      "     0     0 4190589.47    0  114 4309957.00 4190589.47  2.77%     -    0s\n",
      "     0     0 4190650.28    0  114 4309957.00 4190650.28  2.77%     -    0s\n",
      "     0     0 4191078.69    0  111 4309957.00 4191078.69  2.76%     -    0s\n",
      "     0     0 4191304.61    0  111 4309957.00 4191304.61  2.75%     -    0s\n",
      "     0     0 4193009.30    0  111 4309957.00 4193009.30  2.71%     -    0s\n",
      "H    0     0                    4309178.0000 4193009.30  2.70%     -    0s\n",
      "     0     0 4193486.96    0  110 4309178.00 4193486.96  2.68%     -    0s\n",
      "     0     0 4195127.64    0  106 4309178.00 4195127.64  2.65%     -    0s\n",
      "     0     0 4195182.00    0  109 4309178.00 4195182.00  2.65%     -    0s\n",
      "     0     0 4196303.97    0  103 4309178.00 4196303.97  2.62%     -    0s\n",
      "     0     0 4196539.20    0  103 4309178.00 4196539.20  2.61%     -    0s\n",
      "     0     2 4197138.35    0  103 4309178.00 4197138.35  2.60%     -    0s\n",
      "H  123    69                    4292938.0000 4235052.65  1.35%  17.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  Cover: 32\n",
      "  MIR: 32\n",
      "  StrongCG: 15\n",
      "  RLT: 4\n",
      "\n",
      "Explored 240 nodes (4339 simplex iterations) in 0.30 seconds (0.11 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 4.29294e+06 4.30918e+06 4.30996e+06 ... 4.45216e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.292938000000e+06, best bound 4.292938000000e+06, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Optimize the model\n",
    "model.optimize()\n",
    "\n",
    "# model.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16eebf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model output\n",
    "\n",
    "def print_full_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            print(f\"Y[{s},{v}] = {y[s,v]}\")\n",
    "\n",
    "def print_concise_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                if x[e,s,v].x:\n",
    "                    print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            if y[s,v].x:\n",
    "                print(f\"Y[{s},{v}] = {y[s,v]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a6825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization successful!\n",
      "Optimal X [endpoint, server, video] values:\n",
      "X[0,0,7] * 170 = <gurobi.Var x[0,0,7] (value 1.0)>\n",
      "X[0,0,31] * 170 = <gurobi.Var x[0,0,31] (value 1.0)>\n",
      "X[0,1,1] * 22 = <gurobi.Var x[0,1,1] (value 1.0)>\n",
      "X[0,1,15] * 22 = <gurobi.Var x[0,1,15] (value 1.0)>\n",
      "X[0,1,65] * 22 = <gurobi.Var x[0,1,65] (value 1.0)>\n",
      "X[0,1,99] * 22 = <gurobi.Var x[0,1,99] (value 1.0)>\n",
      "X[0,2,8] * 224 = <gurobi.Var x[0,2,8] (value 1.0)>\n",
      "X[0,2,13] * 224 = <gurobi.Var x[0,2,13] (value 1.0)>\n",
      "X[0,10,26] * 1013 = <gurobi.Var x[0,10,26] (value 1.0)>\n",
      "X[1,0,5] * 7 = <gurobi.Var x[1,0,5] (value 1.0)>\n",
      "X[1,0,7] * 7 = <gurobi.Var x[1,0,7] (value 1.0)>\n",
      "X[1,0,10] * 7 = <gurobi.Var x[1,0,10] (value 1.0)>\n",
      "X[1,0,46] * 7 = <gurobi.Var x[1,0,46] (value 1.0)>\n",
      "X[1,1,0] * 50 = <gurobi.Var x[1,1,0] (value 1.0)>\n",
      "X[1,1,1] * 50 = <gurobi.Var x[1,1,1] (value 1.0)>\n",
      "X[1,10,89] * 696 = <gurobi.Var x[1,10,89] (value 1.0)>\n",
      "X[2,4,8] * 175 = <gurobi.Var x[2,4,8] (value 1.0)>\n",
      "X[2,4,17] * 175 = <gurobi.Var x[2,4,17] (value 1.0)>\n",
      "X[2,4,81] * 175 = <gurobi.Var x[2,4,81] (value 1.0)>\n",
      "X[2,5,0] * 2 = <gurobi.Var x[2,5,0] (value 1.0)>\n",
      "X[2,5,7] * 2 = <gurobi.Var x[2,5,7] (value 1.0)>\n",
      "X[2,5,10] * 2 = <gurobi.Var x[2,5,10] (value 1.0)>\n",
      "X[2,5,13] * 2 = <gurobi.Var x[2,5,13] (value 1.0)>\n",
      "X[2,5,32] * 2 = <gurobi.Var x[2,5,32] (value 1.0)>\n",
      "X[2,10,3] * 1114 = <gurobi.Var x[2,10,3] (value 1.0)>\n",
      "X[3,1,0] * 24 = <gurobi.Var x[3,1,0] (value 1.0)>\n",
      "X[3,1,1] * 24 = <gurobi.Var x[3,1,1] (value 1.0)>\n",
      "X[3,1,10] * 24 = <gurobi.Var x[3,1,10] (value 1.0)>\n",
      "X[3,8,2] * 25 = <gurobi.Var x[3,8,2] (value 1.0)>\n",
      "X[3,8,3] * 25 = <gurobi.Var x[3,8,3] (value 1.0)>\n",
      "X[3,8,6] * 25 = <gurobi.Var x[3,8,6] (value 1.0)>\n",
      "X[3,8,16] * 25 = <gurobi.Var x[3,8,16] (value 1.0)>\n",
      "X[3,10,34] * 464 = <gurobi.Var x[3,10,34] (value 1.0)>\n",
      "X[4,3,8] * 216 = <gurobi.Var x[4,3,8] (value 1.0)>\n",
      "X[4,5,0] * 155 = <gurobi.Var x[4,5,0] (value 1.0)>\n",
      "X[4,6,27] * 139 = <gurobi.Var x[4,6,27] (value 1.0)>\n",
      "X[4,7,24] * 208 = <gurobi.Var x[4,7,24] (value 1.0)>\n",
      "X[4,7,54] * 208 = <gurobi.Var x[4,7,54] (value 1.0)>\n",
      "X[4,8,2] * 145 = <gurobi.Var x[4,8,2] (value 1.0)>\n",
      "X[4,8,3] * 145 = <gurobi.Var x[4,8,3] (value 1.0)>\n",
      "X[4,10,26] * 522 = <gurobi.Var x[4,10,26] (value 1.0)>\n",
      "X[5,0,5] * 26 = <gurobi.Var x[5,0,5] (value 1.0)>\n",
      "X[5,0,16] * 26 = <gurobi.Var x[5,0,16] (value 1.0)>\n",
      "X[5,2,8] * 70 = <gurobi.Var x[5,2,8] (value 1.0)>\n",
      "X[5,2,19] * 70 = <gurobi.Var x[5,2,19] (value 1.0)>\n",
      "X[5,8,2] * 159 = <gurobi.Var x[5,8,2] (value 1.0)>\n",
      "X[5,8,82] * 159 = <gurobi.Var x[5,8,82] (value 1.0)>\n",
      "X[5,9,1] * 92 = <gurobi.Var x[5,9,1] (value 1.0)>\n",
      "X[6,2,4] * 163 = <gurobi.Var x[6,2,4] (value 1.0)>\n",
      "X[6,2,8] * 163 = <gurobi.Var x[6,2,8] (value 1.0)>\n",
      "X[6,2,16] * 163 = <gurobi.Var x[6,2,16] (value 1.0)>\n",
      "X[6,9,0] * 153 = <gurobi.Var x[6,9,0] (value 1.0)>\n",
      "X[6,9,1] * 153 = <gurobi.Var x[6,9,1] (value 1.0)>\n",
      "X[6,9,23] * 153 = <gurobi.Var x[6,9,23] (value 1.0)>\n",
      "X[6,9,43] * 153 = <gurobi.Var x[6,9,43] (value 1.0)>\n",
      "X[6,10,62] * 1288 = <gurobi.Var x[6,10,62] (value 1.0)>\n",
      "X[7,7,1] * 86 = <gurobi.Var x[7,7,1] (value 1.0)>\n",
      "X[7,7,5] * 86 = <gurobi.Var x[7,7,5] (value 1.0)>\n",
      "X[7,7,54] * 86 = <gurobi.Var x[7,7,54] (value 1.0)>\n",
      "X[7,7,74] * 86 = <gurobi.Var x[7,7,74] (value 1.0)>\n",
      "X[7,10,2] * 226 = <gurobi.Var x[7,10,2] (value 1.0)>\n",
      "X[7,10,7] * 226 = <gurobi.Var x[7,10,7] (value 1.0)>\n",
      "X[7,10,11] * 226 = <gurobi.Var x[7,10,11] (value 1.0)>\n",
      "X[7,10,65] * 226 = <gurobi.Var x[7,10,65] (value 1.0)>\n",
      "X[8,5,0] * 79 = <gurobi.Var x[8,5,0] (value 1.0)>\n",
      "X[8,5,13] * 79 = <gurobi.Var x[8,5,13] (value 1.0)>\n",
      "X[8,6,4] * 9 = <gurobi.Var x[8,6,4] (value 1.0)>\n",
      "X[8,6,16] * 9 = <gurobi.Var x[8,6,16] (value 1.0)>\n",
      "X[8,6,21] * 9 = <gurobi.Var x[8,6,21] (value 1.0)>\n",
      "X[8,6,30] * 9 = <gurobi.Var x[8,6,30] (value 1.0)>\n",
      "X[8,7,1] * 53 = <gurobi.Var x[8,7,1] (value 1.0)>\n",
      "X[8,8,3] * 67 = <gurobi.Var x[8,8,3] (value 1.0)>\n",
      "X[8,10,44] * 316 = <gurobi.Var x[8,10,44] (value 1.0)>\n",
      "X[9,3,4] * 62 = <gurobi.Var x[9,3,4] (value 1.0)>\n",
      "X[9,3,5] * 62 = <gurobi.Var x[9,3,5] (value 1.0)>\n",
      "X[9,3,10] * 62 = <gurobi.Var x[9,3,10] (value 1.0)>\n",
      "X[9,3,16] * 62 = <gurobi.Var x[9,3,16] (value 1.0)>\n",
      "X[9,3,30] * 62 = <gurobi.Var x[9,3,30] (value 1.0)>\n",
      "X[9,9,0] * 66 = <gurobi.Var x[9,9,0] (value 1.0)>\n",
      "X[9,9,1] * 66 = <gurobi.Var x[9,9,1] (value 1.0)>\n",
      "X[9,10,2] * 365 = <gurobi.Var x[9,10,2] (value 1.0)>\n",
      "\n",
      "Optimal Y [server, video] values:\n",
      "Y[0,5] = <gurobi.Var y[0,5] (value 1.0)>\n",
      "Y[0,7] = <gurobi.Var y[0,7] (value 1.0)>\n",
      "Y[0,10] = <gurobi.Var y[0,10] (value 1.0)>\n",
      "Y[0,16] = <gurobi.Var y[0,16] (value 1.0)>\n",
      "Y[0,31] = <gurobi.Var y[0,31] (value 1.0)>\n",
      "Y[0,46] = <gurobi.Var y[0,46] (value 1.0)>\n",
      "Y[1,0] = <gurobi.Var y[1,0] (value 1.0)>\n",
      "Y[1,1] = <gurobi.Var y[1,1] (value 1.0)>\n",
      "Y[1,10] = <gurobi.Var y[1,10] (value 1.0)>\n",
      "Y[1,15] = <gurobi.Var y[1,15] (value 1.0)>\n",
      "Y[1,65] = <gurobi.Var y[1,65] (value 1.0)>\n",
      "Y[1,99] = <gurobi.Var y[1,99] (value 1.0)>\n",
      "Y[2,4] = <gurobi.Var y[2,4] (value 1.0)>\n",
      "Y[2,8] = <gurobi.Var y[2,8] (value 1.0)>\n",
      "Y[2,13] = <gurobi.Var y[2,13] (value 1.0)>\n",
      "Y[2,16] = <gurobi.Var y[2,16] (value 1.0)>\n",
      "Y[2,19] = <gurobi.Var y[2,19] (value 1.0)>\n",
      "Y[3,4] = <gurobi.Var y[3,4] (value 1.0)>\n",
      "Y[3,5] = <gurobi.Var y[3,5] (value 1.0)>\n",
      "Y[3,8] = <gurobi.Var y[3,8] (value 1.0)>\n",
      "Y[3,10] = <gurobi.Var y[3,10] (value 1.0)>\n",
      "Y[3,16] = <gurobi.Var y[3,16] (value 1.0)>\n",
      "Y[3,30] = <gurobi.Var y[3,30] (value 1.0)>\n",
      "Y[4,8] = <gurobi.Var y[4,8] (value 1.0)>\n",
      "Y[4,17] = <gurobi.Var y[4,17] (value 1.0)>\n",
      "Y[4,81] = <gurobi.Var y[4,81] (value 1.0)>\n",
      "Y[5,0] = <gurobi.Var y[5,0] (value 1.0)>\n",
      "Y[5,7] = <gurobi.Var y[5,7] (value 1.0)>\n",
      "Y[5,10] = <gurobi.Var y[5,10] (value 1.0)>\n",
      "Y[5,13] = <gurobi.Var y[5,13] (value 1.0)>\n",
      "Y[5,32] = <gurobi.Var y[5,32] (value 1.0)>\n",
      "Y[6,4] = <gurobi.Var y[6,4] (value 1.0)>\n",
      "Y[6,16] = <gurobi.Var y[6,16] (value 1.0)>\n",
      "Y[6,21] = <gurobi.Var y[6,21] (value 1.0)>\n",
      "Y[6,27] = <gurobi.Var y[6,27] (value 1.0)>\n",
      "Y[6,30] = <gurobi.Var y[6,30] (value 1.0)>\n",
      "Y[7,1] = <gurobi.Var y[7,1] (value 1.0)>\n",
      "Y[7,5] = <gurobi.Var y[7,5] (value 1.0)>\n",
      "Y[7,24] = <gurobi.Var y[7,24] (value 1.0)>\n",
      "Y[7,54] = <gurobi.Var y[7,54] (value 1.0)>\n",
      "Y[7,74] = <gurobi.Var y[7,74] (value 1.0)>\n",
      "Y[8,2] = <gurobi.Var y[8,2] (value 1.0)>\n",
      "Y[8,3] = <gurobi.Var y[8,3] (value 1.0)>\n",
      "Y[8,6] = <gurobi.Var y[8,6] (value 1.0)>\n",
      "Y[8,16] = <gurobi.Var y[8,16] (value 1.0)>\n",
      "Y[8,82] = <gurobi.Var y[8,82] (value 1.0)>\n",
      "Y[9,0] = <gurobi.Var y[9,0] (value 1.0)>\n",
      "Y[9,1] = <gurobi.Var y[9,1] (value 1.0)>\n",
      "Y[9,23] = <gurobi.Var y[9,23] (value 1.0)>\n",
      "Y[9,43] = <gurobi.Var y[9,43] (value 1.0)>\n",
      "Y[10,0] = <gurobi.Var y[10,0] (value 1.0)>\n",
      "Y[10,1] = <gurobi.Var y[10,1] (value 1.0)>\n",
      "Y[10,2] = <gurobi.Var y[10,2] (value 1.0)>\n",
      "Y[10,3] = <gurobi.Var y[10,3] (value 1.0)>\n",
      "Y[10,4] = <gurobi.Var y[10,4] (value 1.0)>\n",
      "Y[10,5] = <gurobi.Var y[10,5] (value 1.0)>\n",
      "Y[10,6] = <gurobi.Var y[10,6] (value 1.0)>\n",
      "Y[10,7] = <gurobi.Var y[10,7] (value 1.0)>\n",
      "Y[10,8] = <gurobi.Var y[10,8] (value 1.0)>\n",
      "Y[10,9] = <gurobi.Var y[10,9] (value 1.0)>\n",
      "Y[10,10] = <gurobi.Var y[10,10] (value 1.0)>\n",
      "Y[10,11] = <gurobi.Var y[10,11] (value 1.0)>\n",
      "Y[10,12] = <gurobi.Var y[10,12] (value 1.0)>\n",
      "Y[10,13] = <gurobi.Var y[10,13] (value 1.0)>\n",
      "Y[10,14] = <gurobi.Var y[10,14] (value 1.0)>\n",
      "Y[10,15] = <gurobi.Var y[10,15] (value 1.0)>\n",
      "Y[10,16] = <gurobi.Var y[10,16] (value 1.0)>\n",
      "Y[10,17] = <gurobi.Var y[10,17] (value 1.0)>\n",
      "Y[10,18] = <gurobi.Var y[10,18] (value 1.0)>\n",
      "Y[10,19] = <gurobi.Var y[10,19] (value 1.0)>\n",
      "Y[10,20] = <gurobi.Var y[10,20] (value 1.0)>\n",
      "Y[10,21] = <gurobi.Var y[10,21] (value 1.0)>\n",
      "Y[10,22] = <gurobi.Var y[10,22] (value 1.0)>\n",
      "Y[10,23] = <gurobi.Var y[10,23] (value 1.0)>\n",
      "Y[10,24] = <gurobi.Var y[10,24] (value 1.0)>\n",
      "Y[10,25] = <gurobi.Var y[10,25] (value 1.0)>\n",
      "Y[10,26] = <gurobi.Var y[10,26] (value 1.0)>\n",
      "Y[10,27] = <gurobi.Var y[10,27] (value 1.0)>\n",
      "Y[10,28] = <gurobi.Var y[10,28] (value 1.0)>\n",
      "Y[10,29] = <gurobi.Var y[10,29] (value 1.0)>\n",
      "Y[10,30] = <gurobi.Var y[10,30] (value 1.0)>\n",
      "Y[10,31] = <gurobi.Var y[10,31] (value 1.0)>\n",
      "Y[10,32] = <gurobi.Var y[10,32] (value 1.0)>\n",
      "Y[10,33] = <gurobi.Var y[10,33] (value 1.0)>\n",
      "Y[10,34] = <gurobi.Var y[10,34] (value 1.0)>\n",
      "Y[10,35] = <gurobi.Var y[10,35] (value 1.0)>\n",
      "Y[10,36] = <gurobi.Var y[10,36] (value 1.0)>\n",
      "Y[10,37] = <gurobi.Var y[10,37] (value 1.0)>\n",
      "Y[10,38] = <gurobi.Var y[10,38] (value 1.0)>\n",
      "Y[10,39] = <gurobi.Var y[10,39] (value 1.0)>\n",
      "Y[10,40] = <gurobi.Var y[10,40] (value 1.0)>\n",
      "Y[10,41] = <gurobi.Var y[10,41] (value 1.0)>\n",
      "Y[10,42] = <gurobi.Var y[10,42] (value 1.0)>\n",
      "Y[10,43] = <gurobi.Var y[10,43] (value 1.0)>\n",
      "Y[10,44] = <gurobi.Var y[10,44] (value 1.0)>\n",
      "Y[10,45] = <gurobi.Var y[10,45] (value 1.0)>\n",
      "Y[10,46] = <gurobi.Var y[10,46] (value 1.0)>\n",
      "Y[10,47] = <gurobi.Var y[10,47] (value 1.0)>\n",
      "Y[10,48] = <gurobi.Var y[10,48] (value 1.0)>\n",
      "Y[10,49] = <gurobi.Var y[10,49] (value 1.0)>\n",
      "Y[10,50] = <gurobi.Var y[10,50] (value 1.0)>\n",
      "Y[10,51] = <gurobi.Var y[10,51] (value 1.0)>\n",
      "Y[10,52] = <gurobi.Var y[10,52] (value 1.0)>\n",
      "Y[10,53] = <gurobi.Var y[10,53] (value 1.0)>\n",
      "Y[10,54] = <gurobi.Var y[10,54] (value 1.0)>\n",
      "Y[10,55] = <gurobi.Var y[10,55] (value 1.0)>\n",
      "Y[10,56] = <gurobi.Var y[10,56] (value 1.0)>\n",
      "Y[10,57] = <gurobi.Var y[10,57] (value 1.0)>\n",
      "Y[10,58] = <gurobi.Var y[10,58] (value 1.0)>\n",
      "Y[10,59] = <gurobi.Var y[10,59] (value 1.0)>\n",
      "Y[10,60] = <gurobi.Var y[10,60] (value 1.0)>\n",
      "Y[10,61] = <gurobi.Var y[10,61] (value 1.0)>\n",
      "Y[10,62] = <gurobi.Var y[10,62] (value 1.0)>\n",
      "Y[10,63] = <gurobi.Var y[10,63] (value 1.0)>\n",
      "Y[10,64] = <gurobi.Var y[10,64] (value 1.0)>\n",
      "Y[10,65] = <gurobi.Var y[10,65] (value 1.0)>\n",
      "Y[10,66] = <gurobi.Var y[10,66] (value 1.0)>\n",
      "Y[10,67] = <gurobi.Var y[10,67] (value 1.0)>\n",
      "Y[10,68] = <gurobi.Var y[10,68] (value 1.0)>\n",
      "Y[10,69] = <gurobi.Var y[10,69] (value 1.0)>\n",
      "Y[10,70] = <gurobi.Var y[10,70] (value 1.0)>\n",
      "Y[10,71] = <gurobi.Var y[10,71] (value 1.0)>\n",
      "Y[10,72] = <gurobi.Var y[10,72] (value 1.0)>\n",
      "Y[10,73] = <gurobi.Var y[10,73] (value 1.0)>\n",
      "Y[10,74] = <gurobi.Var y[10,74] (value 1.0)>\n",
      "Y[10,75] = <gurobi.Var y[10,75] (value 1.0)>\n",
      "Y[10,76] = <gurobi.Var y[10,76] (value 1.0)>\n",
      "Y[10,77] = <gurobi.Var y[10,77] (value 1.0)>\n",
      "Y[10,78] = <gurobi.Var y[10,78] (value 1.0)>\n",
      "Y[10,79] = <gurobi.Var y[10,79] (value 1.0)>\n",
      "Y[10,80] = <gurobi.Var y[10,80] (value 1.0)>\n",
      "Y[10,81] = <gurobi.Var y[10,81] (value 1.0)>\n",
      "Y[10,82] = <gurobi.Var y[10,82] (value 1.0)>\n",
      "Y[10,83] = <gurobi.Var y[10,83] (value 1.0)>\n",
      "Y[10,84] = <gurobi.Var y[10,84] (value 1.0)>\n",
      "Y[10,85] = <gurobi.Var y[10,85] (value 1.0)>\n",
      "Y[10,86] = <gurobi.Var y[10,86] (value 1.0)>\n",
      "Y[10,87] = <gurobi.Var y[10,87] (value 1.0)>\n",
      "Y[10,88] = <gurobi.Var y[10,88] (value 1.0)>\n",
      "Y[10,89] = <gurobi.Var y[10,89] (value 1.0)>\n",
      "Y[10,90] = <gurobi.Var y[10,90] (value 1.0)>\n",
      "Y[10,91] = <gurobi.Var y[10,91] (value 1.0)>\n",
      "Y[10,92] = <gurobi.Var y[10,92] (value 1.0)>\n",
      "Y[10,93] = <gurobi.Var y[10,93] (value 1.0)>\n",
      "Y[10,94] = <gurobi.Var y[10,94] (value 1.0)>\n",
      "Y[10,95] = <gurobi.Var y[10,95] (value 1.0)>\n",
      "Y[10,96] = <gurobi.Var y[10,96] (value 1.0)>\n",
      "Y[10,97] = <gurobi.Var y[10,97] (value 1.0)>\n",
      "Y[10,98] = <gurobi.Var y[10,98] (value 1.0)>\n",
      "Y[10,99] = <gurobi.Var y[10,99] (value 1.0)>\n",
      "\n",
      "Optimal objective value: 4292938.0\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "if model.status == gp.GRB.OPTIMAL:\n",
    "    print(\"\\nOptimization successful!\")\n",
    "    # print_full_output()\n",
    "    print_concise_output()\n",
    "    print(f\"\\nOptimal objective value: {model.objVal}\")\n",
    "    OPTIMAL_SOLUTION = model.ObjVal\n",
    "elif model.status == gp.GRB.INFEASIBLE:\n",
    "    print(\"Model is infeasible.\")\n",
    "elif model.status == gp.GRB.UNBOUNDED:\n",
    "    print(\"Model is unbounded.\")\n",
    "else:\n",
    "    print(f\"Optimization ended with status {model.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13b29c",
   "metadata": {},
   "source": [
    "---\n",
    "# Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c355ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common\n",
    "def compute_obj_func(x):\n",
    "    return sum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "\n",
    "x_sol = [] # save X matrix of greedy's solution to use it later in tabu search\n",
    "y_sol = [] # same for Y matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09de88",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d547ffa",
   "metadata": {},
   "source": [
    "### 1\n",
    "order videos by request number, and for every endpoint retrieven from this ordered list place all its requested videos in best available caches for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "039aa21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6347627.0 - GAP: 47.86207021857758% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs.extend((e, v) for v in sorted_vs)\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) \n",
    "y = np.zeros(((num_server+1), num_video)) \n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req in sorted_reqs:\n",
    "    req_endpoint = req[E_IND]\n",
    "    req_video = req[V_IND]\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9e886",
   "metadata": {},
   "source": [
    "### 2\n",
    "order videos by request number, use a round robin schedule to choose an endpoint retrieven from this ordered list and place its remaining requested video in best available cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0775a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 7091338.0 - GAP: 65.18612661072673% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = defaultdict(list)\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs[e] = sorted_vs\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "Done = False\n",
    "endpoints_req_index = [0 for _ in server_index]\n",
    "while not Done:\n",
    "    Done = True\n",
    "    for curr_endpoint in endpoint_index:\n",
    "        curr_endpoint_req_index = endpoints_req_index[curr_endpoint]\n",
    "        \n",
    "        if curr_endpoint_req_index < len(sorted_reqs[curr_endpoint]):\n",
    "            Done = False # There could still be reqs not satisfied other than this\n",
    "            req_video = sorted_reqs[curr_endpoint][curr_endpoint_req_index]\n",
    "            req_video_size = video_size[req_video]\n",
    "\n",
    "            for curr_cache_index in sorted_latency[curr_endpoint]:\n",
    "                if y[curr_cache_index, req_video]:\n",
    "                    x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                        curr_capacity[curr_cache_index] -= req_video_size\n",
    "                        y[curr_cache_index, req_video] = 1\n",
    "                        x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                        break\n",
    "                    \n",
    "        endpoints_req_index[curr_endpoint] += 1\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87489dbd",
   "metadata": {},
   "source": [
    "### 3\n",
    "order videos by request number without considering the endpoints, place them in the best available cache server for the requester endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e34ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6776093.0 - GAP: 57.842787387099456% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "sorted_reqs = sorted(\n",
    "    [(e, v) for e in range(len(reqs)) for v in reqs[e] if reqs[e][v] != 0],\n",
    "    key=lambda pair: reqs[pair[0]][pair[1]],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req_endpoint,req_video in sorted_reqs:\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dd1d5",
   "metadata": {},
   "source": [
    "### 4\n",
    "order videos by request number, place them in the cache connected with most endpoints that have requested that specific video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa52075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9816241.0 - GAP: 128.66020892917624% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "video_req_count = [0 for _ in video_index]\n",
    "num_connected_endpoint = defaultdict(lambda: defaultdict(int)) # used to find best cache to place a video [server][video][latency sum / num endpoint / score]\n",
    "\n",
    "for curr_endpoint_index, endpoint_reqs in reqs.items():\n",
    "    for curr_video_index, req_num in endpoint_reqs.items():\n",
    "        if req_num: # check if requests from endpoint for the video exists\n",
    "            video_req_count[curr_video_index] += req_num\n",
    "            for curr_server_index, lat in latency[curr_endpoint_index].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    num_connected_endpoint[curr_server_index][curr_video_index] += 1\n",
    "            \n",
    "sorted_video_indexes = sorted(range(num_video), key=lambda i: video_req_count[i], reverse=True)\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "# print(curr_capacity)\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    # Sort v indices by ascending value for this e\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "for curr_video_index in sorted_video_indexes:\n",
    "    # now sort caches to get the ones with most connected endpoints that have requested video: curr_video_index\n",
    "    for curr_server_index in sorted(\n",
    "        [\n",
    "            i\n",
    "            for i in range(len(num_connected_endpoint))\n",
    "            if num_connected_endpoint[i][curr_video_index]!= 0\n",
    "        ],\n",
    "        key=lambda i: num_connected_endpoint[i][curr_video_index],\n",
    "        reverse=True\n",
    "    ):\n",
    "        if not y[curr_server_index, curr_video_index]:\n",
    "            if curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "                curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "                y[curr_server_index, curr_video_index] = 1\n",
    "                break\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66908d",
   "metadata": {},
   "source": [
    "### 5\n",
    "iterate trough every cache, place their most requested video from connected endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702ccb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9519517.0 - GAP: 121.74829918344965% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "\n",
    "# get total possible reqs for any cache server from its connected endpoints\n",
    "server_total_reqs = defaultdict(lambda: defaultdict(int))\n",
    "for req_endpoint,req_videos in reqs.items():\n",
    "    for curr_server_index, lat in latency[req_endpoint].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    for curr_video_index in req_videos.keys():\n",
    "                        server_total_reqs[curr_server_index][curr_video_index] += req_videos[curr_video_index]\n",
    "\n",
    "\n",
    "# place video in caches based on request counts\n",
    "for curr_server_index in server_index[:-1]:\n",
    "    sorted_indexes_only = [\n",
    "        video_index\n",
    "        for video_index, count in sorted(\n",
    "            server_total_reqs[curr_server_index].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        if count > 0\n",
    "    ]\n",
    "    for curr_video_index in sorted_indexes_only:\n",
    "        if not y[curr_server_index, curr_video_index] and curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "            curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "            y[curr_server_index, curr_video_index] = 1\n",
    "\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63615d",
   "metadata": {},
   "source": [
    "## Local Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0c175",
   "metadata": {},
   "source": [
    "### tabu search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ff2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfy endpoints request considering the video placements from passed Y matrix\n",
    "def get_best_x(y):\n",
    "    x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "\n",
    "    # Sort server s latency for endpoint e\n",
    "    sorted_latency = defaultdict(list)\n",
    "    for e in latency:\n",
    "        sorted_s = sorted(\n",
    "            [s for s in latency[e] if latency[e][s] != 0],\n",
    "            key=lambda s: latency[e][s]\n",
    "        )\n",
    "        sorted_latency[e] = sorted_s\n",
    "    \n",
    "    for curr_endpoint_index in endpoint_index:\n",
    "        for curr_video_index in reqs[curr_endpoint_index]:\n",
    "            best_server_index = num_server  # default to datacenter\n",
    "            \n",
    "            for curr_server_index in sorted_latency[curr_endpoint_index]:                    \n",
    "                if y[curr_server_index][curr_video_index]:\n",
    "                    best_server_index = curr_server_index\n",
    "                    break\n",
    "\n",
    "            x[curr_endpoint_index][best_server_index][curr_video_index] = 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5369a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_toggle(x, y, num_iters=1000, tabu_list_dim=10, max_no_improve=100):\n",
    "    tabu_list = deque(maxlen=tabu_list_dim)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "    no_improve_count = 0  \n",
    "    \n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                \n",
    "                if move in tabu_list:\n",
    "                    # ASPIRATION CRITERIA    \n",
    "                    if random.random() > 0.2:\n",
    "                        continue\n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                new_y[curr_server_index][curr_video_index] = 1 - new_y[curr_server_index][curr_video_index]\n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "            no_improve_count = 0 # reset no consecutive improvement counter\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            \n",
    "        if no_improve_count >= max_no_improve:\n",
    "            print(f\"Early stopping after {no_improve_count} iterations without improvement.\")\n",
    "            break\n",
    "        \n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # INTENSIFICATION CRITERIA\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136e156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_add(x, y, num_iters=1000, tabu_list_dim=10, max_no_improve=100):\n",
    "    tabu_list = deque(maxlen=tabu_list_dim)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "    no_improve_count = 0  \n",
    "    \n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                \n",
    "                if move in tabu_list:\n",
    "                    # ASPIRATION CRITERIA    \n",
    "                    if random.random() > 0.2:\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                \n",
    "                # Try adding current video in current server if not already present\n",
    "                if new_y[curr_server_index][curr_video_index]:\n",
    "                    continue\n",
    "                new_y[curr_server_index][curr_video_index] = 1 \n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "            no_improve_count = 0 # reset no consecutive improvement counter\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            \n",
    "        if no_improve_count >= max_no_improve:\n",
    "            print(f\"Early stopping after {no_improve_count} iterations without improvement.\")\n",
    "            break\n",
    "\n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # INTENSIFICATION CRITERIA\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a24d4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best sol: 4292938.0\n",
      "Early stopping after 100 iterations without improvement.\n",
      "\n",
      "old solution: 6347627.0, tabu toggle sol: 6347627.0, new GAP: 47.86207021857758\n",
      "old solution: 6347627.0, tabu add sol: 6347627.0, new GAP: 47.86207021857758\n",
      "Early stopping after 100 iterations without improvement.\n",
      "\n",
      "old solution: 7091338.0, tabu toggle sol: 7091338.0, new GAP: 65.18612661072673\n",
      "old solution: 7091338.0, tabu add sol: 7091338.0, new GAP: 65.18612661072673\n",
      "Early stopping after 100 iterations without improvement.\n",
      "\n",
      "old solution: 6776093.0, tabu toggle sol: 6776093.0, new GAP: 57.842787387099456\n",
      "old solution: 6776093.0, tabu add sol: 6776093.0, new GAP: 57.842787387099456\n",
      "Early stopping after 100 iterations without improvement.\n",
      "\n",
      "old solution: 9816241.0, tabu toggle sol: 7161592.0, new GAP: 66.82262823269286\n",
      "old solution: 9816241.0, tabu add sol: 7275848.0, new GAP: 69.48411554045272\n",
      "Early stopping after 100 iterations without improvement.\n",
      "\n",
      "old solution: 9519517.0, tabu toggle sol: 9013457.0, new GAP: 109.96010191621681\n",
      "old solution: 9519517.0, tabu add sol: 9511795.0, new GAP: 121.56842237181155\n"
     ]
    }
   ],
   "source": [
    "print(f\"best sol: {OPTIMAL_SOLUTION}\")\n",
    "tabu_list_dim = np.floor(np.sqrt(num_req_descriptions))\n",
    "\n",
    "for sol_index in range(len(x_sol)):\n",
    "    default_obj_val = compute_obj_func(x_sol[sol_index][0])\n",
    "    GAP_DEF = ( abs(OPTIMAL_SOLUTION - default_obj_val) / OPTIMAL_SOLUTION ) * 100\n",
    "\n",
    "    \n",
    "    x_tabu_toggle, y_tabu_toggle, obj_tabu_toggle = tabu_search_toggle(x_sol[sol_index][0], y_sol[sol_index][0], num_iters=700, tabu_list_dim=int(tabu_list_dim))\n",
    "    GAP_TOGGLE = ( abs(OPTIMAL_SOLUTION - obj_tabu_toggle) / OPTIMAL_SOLUTION ) * 100\n",
    "    print(f\"\\nold solution: {default_obj_val}, tabu toggle sol: {obj_tabu_toggle}, new GAP: {GAP_TOGGLE}\")\n",
    "    \n",
    "    x_tabu_add, y_tabu_add, obj_tabu_add = tabu_search_add(x_sol[sol_index][0], y_sol[sol_index][0], num_iters=700, tabu_list_dim=int(tabu_list_dim))\n",
    "    GAP_ADD = ( abs(OPTIMAL_SOLUTION - obj_tabu_add) / OPTIMAL_SOLUTION ) * 100\n",
    "    print(f\"old solution: {default_obj_val}, tabu add sol: {obj_tabu_add}, new GAP: {GAP_ADD}\")\n",
    "    \n",
    "    if obj_tabu_toggle < obj_tabu_add:\n",
    "        if obj_tabu_toggle < default_obj_val:\n",
    "            x_sol.append((x_tabu_toggle, obj_tabu_toggle))\n",
    "            y_sol.append((y_tabu_toggle, obj_tabu_toggle))\n",
    "    else:\n",
    "        if obj_tabu_add < default_obj_val:\n",
    "            x_sol.append((x_tabu_add, obj_tabu_add))\n",
    "            y_sol.append((y_tabu_add, obj_tabu_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7701ef4",
   "metadata": {},
   "source": [
    "## Genetic algorithm\n",
    "\n",
    "#### fitness: minimize delay ( compute_obj_func(x) )\n",
    "#### initial population: heuristics solutions (x_sol & y_sol)\n",
    "#### randomization: montecarlo simulation\n",
    "#### crossover & mutation: on y (update x conseguently get_best_x(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a5db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start = min(x_sol, key=lambda solution: solution[1])\n",
    "best_in_generation_history = [best_start[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0566772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0: Best delay = 5899138.0\n",
      "Gen 1: Best delay = 6363652.0\n",
      "Gen 2: Best delay = 6315358.0\n",
      "Gen 3: Best delay = 6315358.0\n",
      "Gen 4: Best delay = 6315358.0\n",
      "Gen 5: Best delay = 6315358.0\n",
      "Gen 6: Best delay = 6315358.0\n",
      "Gen 7: Best delay = 6013168.0\n",
      "Gen 8: Best delay = 6013168.0\n",
      "Gen 9: Best delay = 6013168.0\n",
      "Gen 10: Best delay = 6013168.0\n",
      "Gen 11: Best delay = 6013168.0\n",
      "Gen 12: Best delay = 6013168.0\n",
      "Gen 13: Best delay = 6013168.0\n",
      "Gen 14: Best delay = 6013168.0\n",
      "Gen 15: Best delay = 6013168.0\n",
      "Gen 16: Best delay = 6013168.0\n",
      "Gen 17: Best delay = 5985708.0\n",
      "Gen 18: Best delay = 5706798.0\n",
      "Gen 19: Best delay = 5706798.0\n",
      "Gen 20: Best delay = 5706798.0\n",
      "Gen 21: Best delay = 5706798.0\n",
      "Gen 22: Best delay = 5706798.0\n",
      "Gen 23: Best delay = 5706798.0\n",
      "Gen 24: Best delay = 5706798.0\n",
      "Gen 25: Best delay = 5706798.0\n",
      "Gen 26: Best delay = 5706798.0\n",
      "Gen 27: Best delay = 5706798.0\n",
      "Gen 28: Best delay = 5706798.0\n",
      "Gen 29: Best delay = 5706798.0\n",
      "Gen 30: Best delay = 5706798.0\n",
      "Gen 31: Best delay = 5706798.0\n",
      "Gen 32: Best delay = 5706798.0\n",
      "Gen 33: Best delay = 5706798.0\n",
      "Gen 34: Best delay = 5706798.0\n",
      "Gen 35: Best delay = 5706798.0\n",
      "Gen 36: Best delay = 5706798.0\n",
      "Gen 37: Best delay = 5706798.0\n",
      "Gen 38: Best delay = 5706798.0\n",
      "Gen 39: Best delay = 5706798.0\n",
      "Gen 40: Best delay = 5706798.0\n",
      "Gen 41: Best delay = 5706798.0\n",
      "Gen 42: Best delay = 5706798.0\n",
      "Gen 43: Best delay = 5706798.0\n",
      "Gen 44: Best delay = 5706798.0\n",
      "Gen 45: Best delay = 5706798.0\n",
      "Gen 46: Best delay = 5706798.0\n",
      "Gen 47: Best delay = 5706798.0\n",
      "Gen 48: Best delay = 5706798.0\n",
      "Gen 49: Best delay = 5706798.0\n",
      "Gen 50: Best delay = 5706798.0\n",
      "Gen 51: Best delay = 5706798.0\n",
      "Gen 52: Best delay = 5706798.0\n",
      "Gen 53: Best delay = 5706798.0\n",
      "Gen 54: Best delay = 5706798.0\n",
      "Gen 55: Best delay = 5706798.0\n",
      "Gen 56: Best delay = 5706798.0\n",
      "Gen 57: Best delay = 5706798.0\n",
      "Gen 58: Best delay = 5706798.0\n",
      "Gen 59: Best delay = 5706798.0\n",
      "Gen 60: Best delay = 5706798.0\n",
      "Gen 61: Best delay = 5706798.0\n",
      "Gen 62: Best delay = 5706798.0\n",
      "Gen 63: Best delay = 5706798.0\n",
      "Gen 64: Best delay = 5706798.0\n",
      "Gen 65: Best delay = 5706798.0\n",
      "Gen 66: Best delay = 5706798.0\n",
      "Gen 67: Best delay = 5706798.0\n",
      "Gen 68: Best delay = 5706798.0\n",
      "Gen 69: Best delay = 5706798.0\n",
      "Gen 70: Best delay = 5706798.0\n",
      "Gen 71: Best delay = 5706798.0\n",
      "Gen 72: Best delay = 5706798.0\n",
      "Gen 73: Best delay = 5706798.0\n",
      "Gen 74: Best delay = 5706798.0\n",
      "Gen 75: Best delay = 5706798.0\n",
      "Gen 76: Best delay = 5706798.0\n",
      "Gen 77: Best delay = 5706798.0\n",
      "Gen 78: Best delay = 5706798.0\n",
      "Gen 79: Best delay = 5706798.0\n",
      "Gen 80: Best delay = 5706798.0\n",
      "Gen 81: Best delay = 5706798.0\n",
      "Gen 82: Best delay = 5706798.0\n",
      "Gen 83: Best delay = 5706798.0\n",
      "Gen 84: Best delay = 5706798.0\n",
      "Gen 85: Best delay = 5706798.0\n",
      "Gen 86: Best delay = 5706798.0\n",
      "Gen 87: Best delay = 5706798.0\n",
      "Gen 88: Best delay = 5706798.0\n",
      "Gen 89: Best delay = 5706798.0\n",
      "Gen 90: Best delay = 5706798.0\n",
      "Gen 91: Best delay = 5706798.0\n",
      "Gen 92: Best delay = 5706798.0\n",
      "Gen 93: Best delay = 5706798.0\n",
      "Gen 94: Best delay = 5706798.0\n",
      "Gen 95: Best delay = 5706798.0\n",
      "Gen 96: Best delay = 5706798.0\n",
      "Gen 97: Best delay = 5706798.0\n",
      "Gen 98: Best delay = 5706798.0\n",
      "Gen 99: Best delay = 5706798.0\n",
      "Gen 100: Best delay = 5706798.0\n",
      "Gen 101: Best delay = 5706798.0\n",
      "Gen 102: Best delay = 5706798.0\n",
      "Gen 103: Best delay = 5706798.0\n",
      "Gen 104: Best delay = 5706798.0\n",
      "Gen 105: Best delay = 5706798.0\n",
      "Gen 106: Best delay = 5706798.0\n",
      "Gen 107: Best delay = 5706798.0\n",
      "Gen 108: Best delay = 5706798.0\n",
      "Gen 109: Best delay = 5706798.0\n",
      "Gen 110: Best delay = 5706798.0\n",
      "Gen 111: Best delay = 5706798.0\n",
      "Gen 112: Best delay = 5706798.0\n",
      "Gen 113: Best delay = 5706798.0\n",
      "Gen 114: Best delay = 5706798.0\n",
      "Gen 115: Best delay = 5706798.0\n",
      "Gen 116: Best delay = 5645507.0\n",
      "Gen 117: Best delay = 5645507.0\n",
      "Gen 118: Best delay = 5645507.0\n",
      "Gen 119: Best delay = 5645507.0\n",
      "Gen 120: Best delay = 5645507.0\n",
      "Gen 121: Best delay = 5645507.0\n",
      "Gen 122: Best delay = 5706798.0\n",
      "Gen 123: Best delay = 5706798.0\n",
      "Gen 124: Best delay = 5706798.0\n",
      "Gen 125: Best delay = 5706798.0\n",
      "Gen 126: Best delay = 5706798.0\n",
      "Gen 127: Best delay = 5645507.0\n",
      "Gen 128: Best delay = 5645507.0\n",
      "Gen 129: Best delay = 5645507.0\n",
      "Gen 130: Best delay = 5645507.0\n",
      "Gen 131: Best delay = 5645507.0\n",
      "Gen 132: Best delay = 5645507.0\n",
      "Gen 133: Best delay = 5645507.0\n",
      "Gen 134: Best delay = 5645507.0\n",
      "Gen 135: Best delay = 5645507.0\n",
      "Gen 136: Best delay = 5645507.0\n",
      "Gen 137: Best delay = 5645507.0\n",
      "Gen 138: Best delay = 5645507.0\n",
      "Gen 139: Best delay = 5645507.0\n",
      "Gen 140: Best delay = 5645507.0\n",
      "Gen 141: Best delay = 5645507.0\n",
      "Gen 142: Best delay = 5645507.0\n",
      "Gen 143: Best delay = 5645507.0\n",
      "Gen 144: Best delay = 5645507.0\n",
      "Gen 145: Best delay = 5648890.0\n",
      "Gen 146: Best delay = 5648890.0\n",
      "Gen 147: Best delay = 5648890.0\n",
      "Gen 148: Best delay = 5706798.0\n",
      "Gen 149: Best delay = 5706798.0\n",
      "Gen 150: Best delay = 5689639.0\n",
      "Gen 151: Best delay = 5689639.0\n",
      "Gen 152: Best delay = 5689639.0\n",
      "Gen 153: Best delay = 5689639.0\n",
      "Gen 154: Best delay = 5689639.0\n",
      "Gen 155: Best delay = 5648890.0\n",
      "Gen 156: Best delay = 5648890.0\n",
      "Gen 157: Best delay = 5648890.0\n",
      "Gen 158: Best delay = 5648890.0\n",
      "Gen 159: Best delay = 5648890.0\n",
      "Gen 160: Best delay = 5648890.0\n",
      "Gen 161: Best delay = 5648890.0\n",
      "Gen 162: Best delay = 5648890.0\n",
      "Gen 163: Best delay = 5648890.0\n",
      "Gen 164: Best delay = 5648890.0\n",
      "Gen 165: Best delay = 5648890.0\n",
      "Gen 166: Best delay = 5648890.0\n",
      "Gen 167: Best delay = 5648890.0\n",
      "Gen 168: Best delay = 5648890.0\n",
      "Gen 169: Best delay = 5648890.0\n",
      "Gen 170: Best delay = 5648890.0\n",
      "Gen 171: Best delay = 5648890.0\n",
      "Gen 172: Best delay = 5648890.0\n",
      "Gen 173: Best delay = 5648890.0\n",
      "Gen 174: Best delay = 5648890.0\n",
      "Gen 175: Best delay = 5551678.0\n",
      "Gen 176: Best delay = 5551678.0\n",
      "Gen 177: Best delay = 5551678.0\n",
      "Gen 178: Best delay = 5551678.0\n",
      "Gen 179: Best delay = 5551678.0\n",
      "Gen 180: Best delay = 5551678.0\n",
      "Gen 181: Best delay = 5551678.0\n",
      "Gen 182: Best delay = 5551678.0\n",
      "Gen 183: Best delay = 5551678.0\n",
      "Gen 184: Best delay = 5551678.0\n",
      "Gen 185: Best delay = 5551678.0\n",
      "Gen 186: Best delay = 5551678.0\n",
      "Gen 187: Best delay = 5551678.0\n",
      "Gen 188: Best delay = 5551678.0\n",
      "Gen 189: Best delay = 5551678.0\n",
      "Gen 190: Best delay = 5551678.0\n",
      "Gen 191: Best delay = 5551678.0\n",
      "Gen 192: Best delay = 5551678.0\n",
      "Gen 193: Best delay = 5551678.0\n",
      "Gen 194: Best delay = 5551678.0\n",
      "Gen 195: Best delay = 5551678.0\n",
      "Gen 196: Best delay = 5551678.0\n",
      "Gen 197: Best delay = 5551678.0\n",
      "Gen 198: Best delay = 5551678.0\n",
      "Gen 199: Best delay = 5551678.0\n",
      "Gen 200: Best delay = 5551678.0\n",
      "Gen 201: Best delay = 5551678.0\n",
      "Gen 202: Best delay = 5551678.0\n",
      "Gen 203: Best delay = 5551678.0\n",
      "Gen 204: Best delay = 5551678.0\n",
      "Gen 205: Best delay = 5551678.0\n",
      "Gen 206: Best delay = 5551678.0\n",
      "Gen 207: Best delay = 5551678.0\n",
      "Gen 208: Best delay = 5352201.0\n",
      "Gen 209: Best delay = 5352201.0\n",
      "Gen 210: Best delay = 5352201.0\n",
      "Gen 211: Best delay = 5352201.0\n",
      "Gen 212: Best delay = 5352201.0\n",
      "Gen 213: Best delay = 5352201.0\n",
      "Gen 214: Best delay = 5352201.0\n",
      "Gen 215: Best delay = 5551678.0\n",
      "Gen 216: Best delay = 5551678.0\n",
      "Gen 217: Best delay = 5551678.0\n",
      "Gen 218: Best delay = 5551678.0\n",
      "Gen 219: Best delay = 5551678.0\n",
      "Gen 220: Best delay = 5551678.0\n",
      "Gen 221: Best delay = 5551678.0\n",
      "Gen 222: Best delay = 5551678.0\n",
      "Gen 223: Best delay = 5551678.0\n",
      "Gen 224: Best delay = 5551678.0\n",
      "Gen 225: Best delay = 5352201.0\n",
      "Gen 226: Best delay = 5352201.0\n",
      "Gen 227: Best delay = 5352201.0\n",
      "Gen 228: Best delay = 5352201.0\n",
      "Gen 229: Best delay = 5352201.0\n",
      "Gen 230: Best delay = 5352201.0\n",
      "Gen 231: Best delay = 5352201.0\n",
      "Gen 232: Best delay = 5352201.0\n",
      "Gen 233: Best delay = 5352201.0\n",
      "Gen 234: Best delay = 5352201.0\n",
      "Gen 235: Best delay = 5352201.0\n",
      "Gen 236: Best delay = 5352201.0\n",
      "Gen 237: Best delay = 5352201.0\n",
      "Gen 238: Best delay = 5352201.0\n",
      "Gen 239: Best delay = 5352201.0\n",
      "Gen 240: Best delay = 5352201.0\n",
      "Gen 241: Best delay = 5352201.0\n",
      "Gen 242: Best delay = 5352201.0\n",
      "Gen 243: Best delay = 5352201.0\n",
      "Gen 244: Best delay = 5352201.0\n",
      "Gen 245: Best delay = 5352201.0\n",
      "Gen 246: Best delay = 5352201.0\n",
      "Gen 247: Best delay = 5352201.0\n",
      "Gen 248: Best delay = 5352201.0\n",
      "Gen 249: Best delay = 5352201.0\n",
      "Gen 250: Best delay = 5352201.0\n",
      "Gen 251: Best delay = 5352201.0\n",
      "Gen 252: Best delay = 5352201.0\n",
      "Gen 253: Best delay = 5352201.0\n",
      "Gen 254: Best delay = 5352201.0\n",
      "Gen 255: Best delay = 5352201.0\n",
      "Gen 256: Best delay = 5352201.0\n",
      "Gen 257: Best delay = 5352201.0\n",
      "Gen 258: Best delay = 5352201.0\n",
      "Gen 259: Best delay = 5352201.0\n",
      "Gen 260: Best delay = 5396659.0\n",
      "Gen 261: Best delay = 5396659.0\n",
      "Gen 262: Best delay = 5352201.0\n",
      "Gen 263: Best delay = 5352201.0\n",
      "Gen 264: Best delay = 5352201.0\n",
      "Gen 265: Best delay = 5352201.0\n",
      "Gen 266: Best delay = 5352201.0\n",
      "Gen 267: Best delay = 5352201.0\n",
      "Gen 268: Best delay = 5352201.0\n",
      "Gen 269: Best delay = 5352201.0\n",
      "Gen 270: Best delay = 5352201.0\n",
      "Gen 271: Best delay = 5352201.0\n",
      "Gen 272: Best delay = 5352201.0\n",
      "Gen 273: Best delay = 5352201.0\n",
      "Gen 274: Best delay = 5352201.0\n",
      "Gen 275: Best delay = 5551678.0\n",
      "Gen 276: Best delay = 5551678.0\n",
      "Gen 277: Best delay = 5352201.0\n",
      "Gen 278: Best delay = 5352201.0\n",
      "Gen 279: Best delay = 5352201.0\n",
      "Gen 280: Best delay = 5352201.0\n",
      "Gen 281: Best delay = 5352201.0\n",
      "Gen 282: Best delay = 5352201.0\n",
      "Gen 283: Best delay = 5352201.0\n",
      "Gen 284: Best delay = 5352201.0\n",
      "Gen 285: Best delay = 5352201.0\n",
      "Gen 286: Best delay = 5352201.0\n",
      "Gen 287: Best delay = 5352201.0\n",
      "Gen 288: Best delay = 5352201.0\n",
      "Gen 289: Best delay = 5352201.0\n",
      "Gen 290: Best delay = 5352201.0\n",
      "Gen 291: Best delay = 5352201.0\n",
      "Gen 292: Best delay = 5352201.0\n",
      "Gen 293: Best delay = 5352201.0\n",
      "Gen 294: Best delay = 5352201.0\n",
      "Gen 295: Best delay = 5352201.0\n",
      "Gen 296: Best delay = 5352201.0\n",
      "Gen 297: Best delay = 5352201.0\n",
      "Gen 298: Best delay = 5352201.0\n",
      "Gen 299: Best delay = 5352201.0\n",
      "Gen 300: Best delay = 5352201.0\n",
      "Gen 301: Best delay = 5352201.0\n",
      "Gen 302: Best delay = 5352201.0\n",
      "Gen 303: Best delay = 5352201.0\n",
      "Gen 304: Best delay = 5352201.0\n",
      "Gen 305: Best delay = 5352201.0\n",
      "Gen 306: Best delay = 5352201.0\n",
      "Gen 307: Best delay = 5352201.0\n",
      "Gen 308: Best delay = 5352201.0\n",
      "Gen 309: Best delay = 5352201.0\n",
      "Gen 310: Best delay = 5352201.0\n",
      "Gen 311: Best delay = 5352201.0\n",
      "Gen 312: Best delay = 5352201.0\n",
      "Gen 313: Best delay = 5352201.0\n",
      "Gen 314: Best delay = 5352201.0\n",
      "Gen 315: Best delay = 5352201.0\n",
      "Gen 316: Best delay = 5352201.0\n",
      "Gen 317: Best delay = 5352201.0\n",
      "Gen 318: Best delay = 5352201.0\n",
      "Gen 319: Best delay = 5352201.0\n",
      "Gen 320: Best delay = 5352201.0\n",
      "Gen 321: Best delay = 5352201.0\n",
      "Gen 322: Best delay = 5352201.0\n",
      "Gen 323: Best delay = 5352201.0\n",
      "Gen 324: Best delay = 5352201.0\n",
      "Gen 325: Best delay = 5352201.0\n",
      "Gen 326: Best delay = 5352201.0\n",
      "Gen 327: Best delay = 5352201.0\n",
      "Gen 328: Best delay = 5352201.0\n",
      "Gen 329: Best delay = 5352201.0\n",
      "Gen 330: Best delay = 5352201.0\n",
      "Gen 331: Best delay = 5352201.0\n",
      "Gen 332: Best delay = 5352201.0\n",
      "Gen 333: Best delay = 5352201.0\n",
      "Gen 334: Best delay = 5352201.0\n",
      "Gen 335: Best delay = 5352201.0\n",
      "Gen 336: Best delay = 5352201.0\n",
      "Gen 337: Best delay = 5352201.0\n",
      "Gen 338: Best delay = 5352201.0\n",
      "Gen 339: Best delay = 5352201.0\n",
      "Gen 340: Best delay = 5352201.0\n",
      "Gen 341: Best delay = 5352201.0\n",
      "Gen 342: Best delay = 5352201.0\n",
      "Gen 343: Best delay = 5352201.0\n",
      "Gen 344: Best delay = 5352201.0\n",
      "Gen 345: Best delay = 5352201.0\n",
      "Gen 346: Best delay = 5352201.0\n",
      "Gen 347: Best delay = 5352201.0\n",
      "Gen 348: Best delay = 5352201.0\n",
      "Gen 349: Best delay = 5352201.0\n",
      "Gen 350: Best delay = 5352201.0\n",
      "Gen 351: Best delay = 5352201.0\n",
      "Gen 352: Best delay = 5352201.0\n",
      "Gen 353: Best delay = 5352201.0\n",
      "Gen 354: Best delay = 5352201.0\n",
      "Gen 355: Best delay = 5352201.0\n",
      "Gen 356: Best delay = 5352201.0\n",
      "Gen 357: Best delay = 5352201.0\n",
      "Gen 358: Best delay = 5352201.0\n",
      "Gen 359: Best delay = 5352201.0\n",
      "Gen 360: Best delay = 5352201.0\n",
      "Gen 361: Best delay = 5352201.0\n",
      "Gen 362: Best delay = 5352201.0\n",
      "Gen 363: Best delay = 5352201.0\n",
      "Gen 364: Best delay = 5352201.0\n",
      "Gen 365: Best delay = 5352201.0\n",
      "Gen 366: Best delay = 5352201.0\n",
      "Gen 367: Best delay = 5352201.0\n",
      "Gen 368: Best delay = 5352201.0\n",
      "Gen 369: Best delay = 5352201.0\n",
      "Gen 370: Best delay = 5352201.0\n",
      "Gen 371: Best delay = 5352201.0\n",
      "Gen 372: Best delay = 5352201.0\n",
      "Gen 373: Best delay = 5352201.0\n",
      "Gen 374: Best delay = 5352201.0\n",
      "Gen 375: Best delay = 5352201.0\n",
      "Gen 376: Best delay = 5352201.0\n",
      "Gen 377: Best delay = 5352201.0\n",
      "Gen 378: Best delay = 5352201.0\n",
      "Gen 379: Best delay = 5352201.0\n",
      "Gen 380: Best delay = 5352201.0\n",
      "Gen 381: Best delay = 5352201.0\n",
      "Gen 382: Best delay = 5352201.0\n",
      "Gen 383: Best delay = 5352201.0\n",
      "Gen 384: Best delay = 5352201.0\n",
      "Gen 385: Best delay = 5352201.0\n",
      "Gen 386: Best delay = 5352201.0\n",
      "Gen 387: Best delay = 5352201.0\n",
      "Gen 388: Best delay = 5352201.0\n",
      "Gen 389: Best delay = 5352201.0\n",
      "Gen 390: Best delay = 5352201.0\n",
      "Gen 391: Best delay = 5352201.0\n",
      "Gen 392: Best delay = 5352201.0\n",
      "Gen 393: Best delay = 5352201.0\n",
      "Gen 394: Best delay = 5352201.0\n",
      "Gen 395: Best delay = 5352201.0\n",
      "Gen 396: Best delay = 5352201.0\n",
      "Gen 397: Best delay = 5352201.0\n",
      "Gen 398: Best delay = 5352201.0\n",
      "Gen 399: Best delay = 5352201.0\n",
      "(array([[[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 1., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 1., 1., 1.]]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 1.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 1., ..., 0., 0., 0.],\n",
      "       [1., 1., 0., ..., 0., 0., 0.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]]), np.float64(5352201.0))\n"
     ]
    }
   ],
   "source": [
    "X_IND = 0\n",
    "Y_IND = 1\n",
    "OBJ_IND = 2\n",
    "\n",
    "NUM_GEN = 400\n",
    "NUM_CROSSOVER_TRIAL = 60\n",
    "NUM_DEAD = 3\n",
    "MUT_RATE = 0.001\n",
    "\n",
    "# check if capacity of any cache is exceeded\n",
    "def is_feasible(y):\n",
    "    for curr_server_index in server_index[:-1]:\n",
    "        curr_tot_size = sum(video_size[curr_video_index] for curr_video_index in video_index if y[curr_server_index, curr_video_index])\n",
    "        if curr_tot_size > cache_capacity:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def montecarlo_roulette_individual_selection(current_population, reverse=False):\n",
    "    # Reverse = True: dead selection - Reverse = False: parent selection\n",
    "    if reverse:\n",
    "        fitness_list = [ curr_individual[OBJ_IND] for curr_individual in current_population ]\n",
    "    else:\n",
    "        # 1 / obj func because less delay must have bigger probility\n",
    "        fitness_list = [ (1/curr_individual[OBJ_IND]) for curr_individual in current_population ]\n",
    "        \n",
    "    fitness_tot = sum(fitness_list)\n",
    "    \n",
    "    spin = random.uniform(0, fitness_tot)\n",
    "    \n",
    "    curr_fit = 0\n",
    "    for curr_individual_index in range(len(current_population)):\n",
    "        curr_fit += fitness_list[curr_individual_index]\n",
    "        if spin < curr_fit:\n",
    "            \n",
    "            if reverse:\n",
    "                return curr_individual_index\n",
    "            \n",
    "            return current_population[curr_individual_index]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    # we need to clone parent or python will reference to them (and if we do mutation we'll do it also on parents)\n",
    "    y1 = parent1[Y_IND].copy()\n",
    "    y2 = parent2[Y_IND].copy()\n",
    "    \n",
    "    childs_y = []\n",
    "    childs = []\n",
    "    \n",
    "    # Monosplit crossover\n",
    "    split = np.random.randint(1, num_server)\n",
    "    # take y cache configuration [0 to split] from parent 1 and remaining cache configuration [split to num_server+1] from parent2 \n",
    "    childs_y.append( np.vstack([y1[:split, :], y2[split:, :]]) )\n",
    "    childs_y.append( np.vstack([y1[:split, :], y2[split:, :]]) )\n",
    "    \n",
    "    for child_y in childs_y:\n",
    "        child_x = get_best_x(child_y)\n",
    "        childs.append((child_x, child_y, compute_obj_func(child_x)))\n",
    "    \n",
    "    return childs\n",
    "\n",
    "def mutate(childs):\n",
    "\n",
    "    childs_mutated = []\n",
    "    \n",
    "    for child in childs:\n",
    "        child_mutated = cp.deepcopy(child)\n",
    "        \n",
    "        for curr_server_index in server_index[:-1]:\n",
    "            for curr_video_index in video_index:\n",
    "                \n",
    "                # mutation is a toggle in y matrix\n",
    "                if random.random() < MUT_RATE:\n",
    "                    child_mutated[Y_IND][curr_server_index][curr_video_index] = 1 - child_mutated[Y_IND][curr_server_index][curr_video_index] \n",
    "        \n",
    "        # check if mutated child is feasible, otherwise keep unmutated one\n",
    "        if is_feasible(child_mutated[Y_IND]):\n",
    "            childs_mutated.append(child_mutated)                    \n",
    "        else:\n",
    "            childs_mutated.append(child)                    \n",
    "            \n",
    "    return childs_mutated\n",
    "\n",
    "def start_genetic():\n",
    "    # an individual is (x, y, objective value)\n",
    "    population = [(x_sol[curr_individual_index][0], y_sol[curr_individual_index][0], x_sol[curr_individual_index][1]) for curr_individual_index in range(len(y_sol))]\n",
    "    # print(f\"Starting population: {population}\")\n",
    "    \n",
    "    for current_gen in range(NUM_GEN):\n",
    "        if population:\n",
    "            for _ in range(NUM_CROSSOVER_TRIAL): \n",
    "                parent_1 = montecarlo_roulette_individual_selection(population)\n",
    "                parent_2 = montecarlo_roulette_individual_selection(population)\n",
    "                childs = crossover(parent_1, parent_2)\n",
    "                childs = mutate(childs)\n",
    "                if childs:\n",
    "                    population.extend(childs)\n",
    "            \n",
    "            # remove an individual every iteration\n",
    "            # for _ in range(NUM_DEAD):\n",
    "            serial_killer_num = len(population) // 10 # floor of 10% of population\n",
    "            for _ in range(serial_killer_num):\n",
    "                dead = montecarlo_roulette_individual_selection(population, reverse=True)\n",
    "                tomb = population.pop(dead)\n",
    "                \n",
    "            if population:\n",
    "                # print(f\"Death individual: {dead} - {tomb}\")\n",
    "                best = min(population, key=lambda individual: individual[OBJ_IND])\n",
    "                best_in_generation_history.append(best[OBJ_IND])\n",
    "                print(f\"Gen {current_gen}: Best delay = {best[OBJ_IND]}\")\n",
    "        else:\n",
    "            return \"GENOCIDE\"\n",
    "        \n",
    "        \n",
    "    return min(population, key=lambda individual: individual[OBJ_IND])\n",
    "\n",
    "sol = start_genetic()\n",
    "best_in_generation_history.append(sol[OBJ_IND])\n",
    "print(f\"{sol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "143591f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Solution GAP: 24.67454689538959\n"
     ]
    }
   ],
   "source": [
    "# PLOT performance\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - best_in_generation_history[-1]) / OPTIMAL_SOLUTION ) * 100\n",
    "GAP_START = ( abs(OPTIMAL_SOLUTION - best_start[1]) / OPTIMAL_SOLUTION ) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(best_in_generation_history, linestyle='-', color=\"m\", label=\"Crossover\")\n",
    "plt.axhline(y=float(best_start[1]), linestyle='--', color=\"y\", label=\"Best Starting Solution\") \n",
    "plt.axhline(y=OPTIMAL_SOLUTION, color='r', linestyle='--', label='Optimal Solution')\n",
    "\n",
    "# best solution GAP\n",
    "plt.plot(len(best_in_generation_history) - 1, best_in_generation_history[-1], marker='D', markersize=10, color='rebeccapurple')\n",
    "plt.text(len(best_in_generation_history) - 10, best_in_generation_history[-1] + 80000,  f'{round(GAP,1)}%', color='rebeccapurple', va='bottom', ha='left')\n",
    "\n",
    "# starting solution GAP\n",
    "plt.plot(1, best_start[1], marker='D', markersize=10, color='darkgoldenrod')\n",
    "plt.text(-9, best_start[1] - 200000,  f'{round(GAP_START,1)}%', color='darkgoldenrod', va='bottom', ha='left')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Crossover\")\n",
    "plt.title(\"Crossover over generations\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Genetic Solution GAP: {GAP}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
