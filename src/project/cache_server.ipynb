{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9903b1c7",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b967f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /shared/University/Algoritmi ottimizzazione combinatoria e su rete/combinatorial-and-network-optimization-algorithm/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b59b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMAL_SOLUTION = 0 # used to evaluate gap between math model and heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28210e55",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6217fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_video = 0\n",
    "num_endpoint = 0\n",
    "num_req_descriptions = 0\n",
    "num_server = 0\n",
    "\n",
    "cache_capacity = 0\n",
    "video_size = []\n",
    "\n",
    "latency = defaultdict(lambda: defaultdict(int))     # [endpoint][cache/datacenter] = latency\n",
    "reqs = defaultdict(lambda: defaultdict(int))        # [endpoint][video] = num reqs\n",
    "\n",
    "# dataset = \"dataset/videos_worth_spreading.in\"\n",
    "dataset = \"dataset/me_at_the_zoo.in\"\n",
    "# dataset = \"dataset/custom.in\"\n",
    "# dataset = \"dataset/minimal.in\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85803ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 0\n",
    "curr_endpoint_index = 0\n",
    "num_connected_cache = 0\n",
    "with open(dataset, \"r\") as f:\n",
    "    for line_content in f:\n",
    "        line = line_content.split()\n",
    "\n",
    "        if status ==0:                                  # get counters\n",
    "            num_video = int(line[0])\n",
    "            num_endpoint = int(line[1])\n",
    "            num_req_descriptions = int(line[2])\n",
    "            num_server = int(line[3])\n",
    "            cache_capacity = int(line[4])\n",
    "            status = 1\n",
    "\n",
    "        elif status == 1:                               # get video dims\n",
    "            for size in line:\n",
    "                video_size.append(int(size))\n",
    "            status = 2\n",
    "\n",
    "        elif status == 2:                               # get datacenter latency and connected cache number\n",
    "            data_center_latency = int(line[0])\n",
    "            latency[curr_endpoint_index][num_server] = data_center_latency\n",
    "            \n",
    "            num_connected_cache = int(line[1])\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "            else:\n",
    "                status = 3\n",
    "        \n",
    "        elif status == 3:                                  # get cache latency\n",
    "            cache_index = int(line[0])\n",
    "            cache_latency = int(line[1])\n",
    "            latency[curr_endpoint_index][cache_index] = cache_latency\n",
    "            \n",
    "            num_connected_cache = num_connected_cache - 1\n",
    "            if not num_connected_cache:\n",
    "                curr_endpoint_index = curr_endpoint_index + 1\n",
    "                if curr_endpoint_index == num_endpoint:\n",
    "                    status = 4\n",
    "                else:\n",
    "                    status = 2\n",
    "        \n",
    "        elif status == 4:                                   # take num requests\n",
    "            video_index = int(line[0])\n",
    "            curr_endpoint_index = int(line[1])\n",
    "            num_reqs = int(line[2])\n",
    "            reqs[curr_endpoint_index][video_index] = num_reqs                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fb2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common indexes\n",
    "endpoint_index = range(num_endpoint)\n",
    "server_index = range(num_server + 1) # I've modelled datacenter as last server\n",
    "video_index = range(num_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861cb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num video: 100, num endpoints 10, req descriptions 100, num cache 10, dim 100\n",
      "video sized: [20, 11, 50, 26, 5, 3, 6, 32, 40, 22, 4, 20, 50, 27, 49, 44, 1, 37, 35, 27, 14, 33, 6, 22, 23, 48, 44, 14, 26, 9, 46, 44, 15, 32, 31, 8, 39, 27, 39, 27, 1, 17, 1, 47, 44, 42, 16, 3, 44, 48, 5, 25, 4, 39, 39, 7, 24, 28, 14, 44, 22, 11, 27, 37, 11, 16, 50, 33, 22, 26, 7, 12, 17, 30, 12, 12, 4, 32, 12, 46, 43, 4, 12, 34, 11, 7, 47, 29, 24, 40, 41, 10, 5, 22, 22, 24, 37, 34, 50, 5]\n",
      "latencies: defaultdict(<function <lambda> at 0x7f9733a71ee0>, {0: defaultdict(<class 'int'>, {10: 1013, 0: 170, 1: 22, 2: 224}), 1: defaultdict(<class 'int'>, {10: 696, 0: 7, 1: 50}), 2: defaultdict(<class 'int'>, {10: 1114, 1: 202, 4: 175, 5: 2}), 3: defaultdict(<class 'int'>, {10: 464, 1: 24, 8: 25}), 4: defaultdict(<class 'int'>, {10: 522, 3: 216, 5: 155, 6: 139, 7: 208, 8: 145}), 5: defaultdict(<class 'int'>, {10: 321, 0: 26, 2: 70, 8: 159, 9: 92}), 6: defaultdict(<class 'int'>, {10: 1288, 2: 163, 9: 153}), 7: defaultdict(<class 'int'>, {10: 226, 7: 86}), 8: defaultdict(<class 'int'>, {10: 316, 4: 236, 5: 79, 6: 9, 7: 53, 8: 67}), 9: defaultdict(<class 'int'>, {10: 365, 2: 225, 3: 62, 5: 141, 6: 147, 9: 66})})\n",
      "reqs: defaultdict(<function <lambda> at 0x7f9733a71da0>, {4: defaultdict(<class 'int'>, {27: 340, 24: 279, 8: 862, 3: 214, 0: 306, 2: 906, 26: 10, 54: 621}), 8: defaultdict(<class 'int'>, {13: 249, 0: 865, 3: 247, 21: 880, 1: 211, 16: 93, 30: 882, 44: 267, 4: 859}), 1: defaultdict(<class 'int'>, {1: 449, 89: 297, 0: 930, 7: 116, 5: 554, 10: 128, 46: 435}), 2: defaultdict(<class 'int'>, {0: 817, 7: 785, 81: 120, 32: 717, 8: 396, 13: 934, 17: 605, 3: 103, 10: 709}), 5: defaultdict(<class 'int'>, {1: 51, 8: 935, 19: 748, 2: 853, 5: 676, 16: 620, 82: 720}), 9: defaultdict(<class 'int'>, {0: 580, 30: 927, 16: 996, 4: 266, 2: 179, 10: 280, 5: 537, 1: 116}), 3: defaultdict(<class 'int'>, {2: 986, 34: 752, 0: 865, 3: 899, 6: 577, 16: 70, 10: 849, 1: 409}), 0: defaultdict(<class 'int'>, {31: 585, 8: 186, 13: 459, 7: 214, 99: 772, 1: 884, 15: 737, 26: 194, 65: 926}), 6: defaultdict(<class 'int'>, {8: 300, 1: 988, 62: 8, 16: 939, 0: 400, 23: 262, 4: 512, 43: 331}), 7: defaultdict(<class 'int'>, {7: 204, 1: 228, 2: 861, 74: 885, 65: 109, 5: 314, 54: 671, 11: 301})})\n"
     ]
    }
   ],
   "source": [
    "print(f\"num video: {num_video}, num endpoints {num_endpoint}, req descriptions {num_req_descriptions}, num cache {num_server}, dim {cache_capacity}\")\n",
    "print(f\"video sized: {video_size}\")\n",
    "print(f\"latencies: {latency}\")\n",
    "print(f\"reqs: {reqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922188b",
   "metadata": {},
   "source": [
    "---\n",
    "# Math model for Guroby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac327f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2635449\n",
      "Academic license - for non-commercial use only - expires 2026-03-12\n",
      "Error: invalid user locale; possible fix is to set the system environment\n",
      "       variable 'LC_ALL' to a valid locale (e.g., to 'C')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 1: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 2: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 3: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 4: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 5: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 6: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 7: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 8: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 9: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 10: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 11: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 12: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 13: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 14: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 15: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 16: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 17: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 18: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 19: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 20: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 21: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 22: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 23: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 24: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 25: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 26: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 27: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 28: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 29: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 30: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 31: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 32: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 33: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 34: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 35: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 36: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 37: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 38: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 39: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 40: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 41: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 42: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 43: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 44: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 45: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 46: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 47: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 48: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 49: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 50: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 51: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 52: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 53: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 54: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 55: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 56: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 57: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 58: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 59: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 60: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 61: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 62: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 63: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 64: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 65: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 66: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 67: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 68: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 69: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 70: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 71: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 72: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 73: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 74: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 75: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 76: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 77: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 78: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 79: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 80: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 81: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 82: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 83: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 84: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 85: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 86: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 87: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 88: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 89: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 90: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 91: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 92: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 93: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 94: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 95: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 96: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 97: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 98: <gurobi.Constr *Awaiting Model Update*>,\n",
       " 99: <gurobi.Constr *Awaiting Model Update*>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gp.Model(\"YoutubeCache\")\n",
    "\n",
    "# DECISION VARS\n",
    "x = model.addVars(endpoint_index, server_index, video_index, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "y = model.addVars(server_index, video_index, vtype=gp.GRB.BINARY, name=\"y\")\n",
    "\n",
    "# OBJECTIVE FUNCTION\n",
    "obj = gp.quicksum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "# the + y[s,v] it's used just to not let place useless video in cache server (but is not needed for this problem)\n",
    "# obj = gp.quicksum((latency[e][s]*reqs[e][v]*x[e,s,v] + y[s,v])for e in endpoint_index for s in server_index for v in video_index)\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "# CONSTRAINTS\n",
    "constr = (gp.quicksum(x[e,s,v] for e in endpoint_index)  <= num_endpoint*y[s,v] for s in server_index for v in video_index )\n",
    "model.addConstrs(constr, name=\"video v must be available on server s to be selected\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for v in video_index ) <= (num_video*latency[e][s]) for e in endpoint_index for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"endpoint can use only existing connection\")\n",
    "\n",
    "constr = ( gp.quicksum( x[e,s,v] for s in server_index ) == (1 if reqs[e][v] else 0) for e in endpoint_index for v in video_index ) # datacenter excluded \n",
    "model.addConstrs(constr, name=\"every request must be satisfied\")\n",
    "\n",
    "constr = ( gp.quicksum(video_size[v] * y[s,v] for v in video_index) <= cache_capacity for s in server_index[:-1] ) # -1 because datacenter have all the video\n",
    "model.addConstrs(constr, name=\"cache capacity\")\n",
    "\n",
    "constr = ( y[num_server,v] == 1 for v in video_index ) # cache servers are from 0 to s-1, s index (num_server) is for datacenter\n",
    "model.addConstrs(constr, name=\"Datacenter have all videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d392c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (linux64 - \"Arch Linux\")\n",
      "\n",
      "CPU model: AMD Ryzen 7 5700U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 2310 rows, 12100 columns and 34200 nonzeros\n",
      "Model fingerprint: 0x8ed62ee6\n",
      "Variable types: 0 continuous, 12100 integer (12100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+01]\n",
      "  Objective range  [2e+02, 1e+06]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Found heuristic solution: objective 1.172420e+07\n",
      "Presolve removed 2169 rows and 11778 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 141 rows, 322 columns, 633 nonzeros\n",
      "Variable types: 0 continuous, 322 integer (322 binary)\n",
      "Found heuristic solution: objective 8551097.0000\n",
      "\n",
      "Root relaxation: objective 3.127974e+06, 126 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3127974.34    0   53 8551097.00 3127974.34  63.4%     -    0s\n",
      "H    0     0                    7118653.0000 3127974.34  56.1%     -    0s\n",
      "H    0     0                    7077316.0000 3127974.34  55.8%     -    0s\n",
      "H    0     0                    6340587.0000 3127974.34  50.7%     -    0s\n",
      "H    0     0                    6039143.0000 3127974.34  48.2%     -    0s\n",
      "H    0     0                    5702303.0000 3127974.34  45.1%     -    0s\n",
      "H    0     0                    5575476.0000 3127974.34  43.9%     -    0s\n",
      "H    0     0                    5437290.0000 3127974.34  42.5%     -    0s\n",
      "H    0     0                    5432136.0000 3745000.72  31.1%     -    0s\n",
      "H    0     0                    5362994.0000 3745000.72  30.2%     -    0s\n",
      "     0     0 3745000.72    0   55 5362994.00 3745000.72  30.2%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 3803552.86    0   53 5362994.00 3803552.86  29.1%     -    0s\n",
      "     0     0 4055513.01    0   59 5362994.00 4055513.01  24.4%     -    0s\n",
      "H    0     0                    5296306.0000 4062646.30  23.3%     -    0s\n",
      "H    0     0                    5292854.0000 4062646.30  23.2%     -    0s\n",
      "     0     0 4062646.30    0   53 5292854.00 4062646.30  23.2%     -    0s\n",
      "H    0     0                    5027784.0000 4078856.01  18.9%     -    0s\n",
      "     0     0 4078856.01    0   84 5027784.00 4078856.01  18.9%     -    0s\n",
      "     0     0 4081298.60    0   81 5027784.00 4081298.60  18.8%     -    0s\n",
      "     0     0 4081471.17    0   78 5027784.00 4081471.17  18.8%     -    0s\n",
      "H    0     0                    4833271.0000 4128023.87  14.6%     -    0s\n",
      "H    0     0                    4452158.0000 4128023.87  7.28%     -    0s\n",
      "H    0     0                    4431398.0000 4128023.87  6.85%     -    0s\n",
      "H    0     0                    4389258.0000 4128023.87  5.95%     -    0s\n",
      "     0     0 4128023.87    0   83 4389258.00 4128023.87  5.95%     -    0s\n",
      "     0     0 4131604.76    0   63 4389258.00 4131604.76  5.87%     -    0s\n",
      "     0     0 4134423.54    0   67 4389258.00 4134423.54  5.81%     -    0s\n",
      "     0     0 4134602.44    0   84 4389258.00 4134602.44  5.80%     -    0s\n",
      "     0     0 4141987.47    0  102 4389258.00 4141987.47  5.63%     -    0s\n",
      "     0     0 4149713.44    0  102 4389258.00 4149713.44  5.46%     -    0s\n",
      "     0     0 4149758.23    0   79 4389258.00 4149758.23  5.46%     -    0s\n",
      "     0     0 4156615.55    0  113 4389258.00 4156615.55  5.30%     -    0s\n",
      "     0     0 4161177.38    0  115 4389258.00 4161177.38  5.20%     -    0s\n",
      "     0     0 4161619.14    0  117 4389258.00 4161619.14  5.19%     -    0s\n",
      "     0     0 4164934.12    0  100 4389258.00 4164934.12  5.11%     -    0s\n",
      "     0     0 4165015.42    0  120 4389258.00 4165015.42  5.11%     -    0s\n",
      "     0     0 4171719.85    0  120 4389258.00 4171719.85  4.96%     -    0s\n",
      "     0     0 4177905.96    0  120 4389258.00 4177905.96  4.82%     -    0s\n",
      "H    0     0                    4381829.0000 4177905.96  4.65%     -    0s\n",
      "H    0     0                    4341105.0000 4177905.96  3.76%     -    0s\n",
      "H    0     0                    4329426.0000 4177905.96  3.50%     -    0s\n",
      "H    0     0                    4320142.0000 4177905.96  3.29%     -    0s\n",
      "     0     0 4177905.96    0   24 4320142.00 4177905.96  3.29%     -    0s\n",
      "H    0     0                    4309957.0000 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0   56 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0   84 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177905.96    0  100 4309957.00 4177905.96  3.06%     -    0s\n",
      "     0     0 4177998.78    0   91 4309957.00 4177998.78  3.06%     -    0s\n",
      "     0     0 4178812.89    0  105 4309957.00 4178812.89  3.04%     -    0s\n",
      "     0     0 4181029.37    0  104 4309957.00 4181029.37  2.99%     -    0s\n",
      "     0     0 4188189.00    0  108 4309957.00 4188189.00  2.83%     -    0s\n",
      "     0     0 4190589.47    0  114 4309957.00 4190589.47  2.77%     -    0s\n",
      "     0     0 4190650.28    0  114 4309957.00 4190650.28  2.77%     -    0s\n",
      "     0     0 4191078.69    0  111 4309957.00 4191078.69  2.76%     -    0s\n",
      "     0     0 4191304.61    0  111 4309957.00 4191304.61  2.75%     -    0s\n",
      "     0     0 4193009.30    0  111 4309957.00 4193009.30  2.71%     -    0s\n",
      "H    0     0                    4309178.0000 4193009.30  2.70%     -    0s\n",
      "     0     0 4193486.96    0  110 4309178.00 4193486.96  2.68%     -    0s\n",
      "     0     0 4195127.64    0  106 4309178.00 4195127.64  2.65%     -    0s\n",
      "     0     0 4195182.00    0  109 4309178.00 4195182.00  2.65%     -    0s\n",
      "     0     0 4196303.97    0  103 4309178.00 4196303.97  2.62%     -    0s\n",
      "     0     0 4196539.20    0  103 4309178.00 4196539.20  2.61%     -    0s\n",
      "     0     2 4197138.35    0  103 4309178.00 4197138.35  2.60%     -    0s\n",
      "H  123    69                    4292938.0000 4235052.65  1.35%  17.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  Cover: 32\n",
      "  MIR: 32\n",
      "  StrongCG: 15\n",
      "  RLT: 4\n",
      "\n",
      "Explored 240 nodes (4339 simplex iterations) in 0.36 seconds (0.11 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 4.29294e+06 4.30918e+06 4.30996e+06 ... 4.45216e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.292938000000e+06, best bound 4.292938000000e+06, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Optimize the model\n",
    "model.optimize()\n",
    "\n",
    "# model.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16eebf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model output\n",
    "\n",
    "def print_full_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            print(f\"Y[{s},{v}] = {y[s,v]}\")\n",
    "\n",
    "def print_concise_output():\n",
    "    print(\"Optimal X [endpoint, server, video] values:\")\n",
    "    for e in endpoint_index:\n",
    "        for s in server_index:\n",
    "            for v in video_index:\n",
    "                if x[e,s,v].x:\n",
    "                    print(f\"X[{e},{s},{v}] * {latency[e][s]} = {x[e,s,v]}\")\n",
    "    print(\"\\nOptimal Y [server, video] values:\")\n",
    "    for s in server_index:\n",
    "        for v in video_index:\n",
    "            if y[s,v].x:\n",
    "                print(f\"Y[{s},{v}] = {y[s,v]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a6825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization successful!\n",
      "Optimal X [endpoint, server, video] values:\n",
      "X[0,0,7] * 170 = <gurobi.Var x[0,0,7] (value 1.0)>\n",
      "X[0,0,31] * 170 = <gurobi.Var x[0,0,31] (value 1.0)>\n",
      "X[0,1,1] * 22 = <gurobi.Var x[0,1,1] (value 1.0)>\n",
      "X[0,1,15] * 22 = <gurobi.Var x[0,1,15] (value 1.0)>\n",
      "X[0,1,65] * 22 = <gurobi.Var x[0,1,65] (value 1.0)>\n",
      "X[0,1,99] * 22 = <gurobi.Var x[0,1,99] (value 1.0)>\n",
      "X[0,2,8] * 224 = <gurobi.Var x[0,2,8] (value 1.0)>\n",
      "X[0,2,13] * 224 = <gurobi.Var x[0,2,13] (value 1.0)>\n",
      "X[0,10,26] * 1013 = <gurobi.Var x[0,10,26] (value 1.0)>\n",
      "X[1,0,5] * 7 = <gurobi.Var x[1,0,5] (value 1.0)>\n",
      "X[1,0,7] * 7 = <gurobi.Var x[1,0,7] (value 1.0)>\n",
      "X[1,0,10] * 7 = <gurobi.Var x[1,0,10] (value 1.0)>\n",
      "X[1,0,46] * 7 = <gurobi.Var x[1,0,46] (value 1.0)>\n",
      "X[1,1,0] * 50 = <gurobi.Var x[1,1,0] (value 1.0)>\n",
      "X[1,1,1] * 50 = <gurobi.Var x[1,1,1] (value 1.0)>\n",
      "X[1,10,89] * 696 = <gurobi.Var x[1,10,89] (value 1.0)>\n",
      "X[2,4,8] * 175 = <gurobi.Var x[2,4,8] (value 1.0)>\n",
      "X[2,4,17] * 175 = <gurobi.Var x[2,4,17] (value 1.0)>\n",
      "X[2,4,81] * 175 = <gurobi.Var x[2,4,81] (value 1.0)>\n",
      "X[2,5,0] * 2 = <gurobi.Var x[2,5,0] (value 1.0)>\n",
      "X[2,5,7] * 2 = <gurobi.Var x[2,5,7] (value 1.0)>\n",
      "X[2,5,10] * 2 = <gurobi.Var x[2,5,10] (value 1.0)>\n",
      "X[2,5,13] * 2 = <gurobi.Var x[2,5,13] (value 1.0)>\n",
      "X[2,5,32] * 2 = <gurobi.Var x[2,5,32] (value 1.0)>\n",
      "X[2,10,3] * 1114 = <gurobi.Var x[2,10,3] (value 1.0)>\n",
      "X[3,1,0] * 24 = <gurobi.Var x[3,1,0] (value 1.0)>\n",
      "X[3,1,1] * 24 = <gurobi.Var x[3,1,1] (value 1.0)>\n",
      "X[3,1,10] * 24 = <gurobi.Var x[3,1,10] (value 1.0)>\n",
      "X[3,8,2] * 25 = <gurobi.Var x[3,8,2] (value 1.0)>\n",
      "X[3,8,3] * 25 = <gurobi.Var x[3,8,3] (value 1.0)>\n",
      "X[3,8,6] * 25 = <gurobi.Var x[3,8,6] (value 1.0)>\n",
      "X[3,8,16] * 25 = <gurobi.Var x[3,8,16] (value 1.0)>\n",
      "X[3,10,34] * 464 = <gurobi.Var x[3,10,34] (value 1.0)>\n",
      "X[4,3,8] * 216 = <gurobi.Var x[4,3,8] (value 1.0)>\n",
      "X[4,5,0] * 155 = <gurobi.Var x[4,5,0] (value 1.0)>\n",
      "X[4,6,27] * 139 = <gurobi.Var x[4,6,27] (value 1.0)>\n",
      "X[4,7,24] * 208 = <gurobi.Var x[4,7,24] (value 1.0)>\n",
      "X[4,7,54] * 208 = <gurobi.Var x[4,7,54] (value 1.0)>\n",
      "X[4,8,2] * 145 = <gurobi.Var x[4,8,2] (value 1.0)>\n",
      "X[4,8,3] * 145 = <gurobi.Var x[4,8,3] (value 1.0)>\n",
      "X[4,10,26] * 522 = <gurobi.Var x[4,10,26] (value 1.0)>\n",
      "X[5,0,5] * 26 = <gurobi.Var x[5,0,5] (value 1.0)>\n",
      "X[5,0,16] * 26 = <gurobi.Var x[5,0,16] (value 1.0)>\n",
      "X[5,2,8] * 70 = <gurobi.Var x[5,2,8] (value 1.0)>\n",
      "X[5,2,19] * 70 = <gurobi.Var x[5,2,19] (value 1.0)>\n",
      "X[5,8,2] * 159 = <gurobi.Var x[5,8,2] (value 1.0)>\n",
      "X[5,8,82] * 159 = <gurobi.Var x[5,8,82] (value 1.0)>\n",
      "X[5,9,1] * 92 = <gurobi.Var x[5,9,1] (value 1.0)>\n",
      "X[6,2,4] * 163 = <gurobi.Var x[6,2,4] (value 1.0)>\n",
      "X[6,2,8] * 163 = <gurobi.Var x[6,2,8] (value 1.0)>\n",
      "X[6,2,16] * 163 = <gurobi.Var x[6,2,16] (value 1.0)>\n",
      "X[6,9,0] * 153 = <gurobi.Var x[6,9,0] (value 1.0)>\n",
      "X[6,9,1] * 153 = <gurobi.Var x[6,9,1] (value 1.0)>\n",
      "X[6,9,23] * 153 = <gurobi.Var x[6,9,23] (value 1.0)>\n",
      "X[6,9,43] * 153 = <gurobi.Var x[6,9,43] (value 1.0)>\n",
      "X[6,10,62] * 1288 = <gurobi.Var x[6,10,62] (value 1.0)>\n",
      "X[7,7,1] * 86 = <gurobi.Var x[7,7,1] (value 1.0)>\n",
      "X[7,7,5] * 86 = <gurobi.Var x[7,7,5] (value 1.0)>\n",
      "X[7,7,54] * 86 = <gurobi.Var x[7,7,54] (value 1.0)>\n",
      "X[7,7,74] * 86 = <gurobi.Var x[7,7,74] (value 1.0)>\n",
      "X[7,10,2] * 226 = <gurobi.Var x[7,10,2] (value 1.0)>\n",
      "X[7,10,7] * 226 = <gurobi.Var x[7,10,7] (value 1.0)>\n",
      "X[7,10,11] * 226 = <gurobi.Var x[7,10,11] (value 1.0)>\n",
      "X[7,10,65] * 226 = <gurobi.Var x[7,10,65] (value 1.0)>\n",
      "X[8,5,0] * 79 = <gurobi.Var x[8,5,0] (value 1.0)>\n",
      "X[8,5,13] * 79 = <gurobi.Var x[8,5,13] (value 1.0)>\n",
      "X[8,6,4] * 9 = <gurobi.Var x[8,6,4] (value 1.0)>\n",
      "X[8,6,16] * 9 = <gurobi.Var x[8,6,16] (value 1.0)>\n",
      "X[8,6,21] * 9 = <gurobi.Var x[8,6,21] (value 1.0)>\n",
      "X[8,6,30] * 9 = <gurobi.Var x[8,6,30] (value 1.0)>\n",
      "X[8,7,1] * 53 = <gurobi.Var x[8,7,1] (value 1.0)>\n",
      "X[8,8,3] * 67 = <gurobi.Var x[8,8,3] (value 1.0)>\n",
      "X[8,10,44] * 316 = <gurobi.Var x[8,10,44] (value 1.0)>\n",
      "X[9,3,4] * 62 = <gurobi.Var x[9,3,4] (value 1.0)>\n",
      "X[9,3,5] * 62 = <gurobi.Var x[9,3,5] (value 1.0)>\n",
      "X[9,3,10] * 62 = <gurobi.Var x[9,3,10] (value 1.0)>\n",
      "X[9,3,16] * 62 = <gurobi.Var x[9,3,16] (value 1.0)>\n",
      "X[9,3,30] * 62 = <gurobi.Var x[9,3,30] (value 1.0)>\n",
      "X[9,9,0] * 66 = <gurobi.Var x[9,9,0] (value 1.0)>\n",
      "X[9,9,1] * 66 = <gurobi.Var x[9,9,1] (value 1.0)>\n",
      "X[9,10,2] * 365 = <gurobi.Var x[9,10,2] (value 1.0)>\n",
      "\n",
      "Optimal Y [server, video] values:\n",
      "Y[0,5] = <gurobi.Var y[0,5] (value 1.0)>\n",
      "Y[0,7] = <gurobi.Var y[0,7] (value 1.0)>\n",
      "Y[0,10] = <gurobi.Var y[0,10] (value 1.0)>\n",
      "Y[0,16] = <gurobi.Var y[0,16] (value 1.0)>\n",
      "Y[0,31] = <gurobi.Var y[0,31] (value 1.0)>\n",
      "Y[0,46] = <gurobi.Var y[0,46] (value 1.0)>\n",
      "Y[1,0] = <gurobi.Var y[1,0] (value 1.0)>\n",
      "Y[1,1] = <gurobi.Var y[1,1] (value 1.0)>\n",
      "Y[1,10] = <gurobi.Var y[1,10] (value 1.0)>\n",
      "Y[1,15] = <gurobi.Var y[1,15] (value 1.0)>\n",
      "Y[1,65] = <gurobi.Var y[1,65] (value 1.0)>\n",
      "Y[1,99] = <gurobi.Var y[1,99] (value 1.0)>\n",
      "Y[2,4] = <gurobi.Var y[2,4] (value 1.0)>\n",
      "Y[2,8] = <gurobi.Var y[2,8] (value 1.0)>\n",
      "Y[2,13] = <gurobi.Var y[2,13] (value 1.0)>\n",
      "Y[2,16] = <gurobi.Var y[2,16] (value 1.0)>\n",
      "Y[2,19] = <gurobi.Var y[2,19] (value 1.0)>\n",
      "Y[3,4] = <gurobi.Var y[3,4] (value 1.0)>\n",
      "Y[3,5] = <gurobi.Var y[3,5] (value 1.0)>\n",
      "Y[3,8] = <gurobi.Var y[3,8] (value 1.0)>\n",
      "Y[3,10] = <gurobi.Var y[3,10] (value 1.0)>\n",
      "Y[3,16] = <gurobi.Var y[3,16] (value 1.0)>\n",
      "Y[3,30] = <gurobi.Var y[3,30] (value 1.0)>\n",
      "Y[4,8] = <gurobi.Var y[4,8] (value 1.0)>\n",
      "Y[4,17] = <gurobi.Var y[4,17] (value 1.0)>\n",
      "Y[4,81] = <gurobi.Var y[4,81] (value 1.0)>\n",
      "Y[5,0] = <gurobi.Var y[5,0] (value 1.0)>\n",
      "Y[5,7] = <gurobi.Var y[5,7] (value 1.0)>\n",
      "Y[5,10] = <gurobi.Var y[5,10] (value 1.0)>\n",
      "Y[5,13] = <gurobi.Var y[5,13] (value 1.0)>\n",
      "Y[5,32] = <gurobi.Var y[5,32] (value 1.0)>\n",
      "Y[6,4] = <gurobi.Var y[6,4] (value 1.0)>\n",
      "Y[6,16] = <gurobi.Var y[6,16] (value 1.0)>\n",
      "Y[6,21] = <gurobi.Var y[6,21] (value 1.0)>\n",
      "Y[6,27] = <gurobi.Var y[6,27] (value 1.0)>\n",
      "Y[6,30] = <gurobi.Var y[6,30] (value 1.0)>\n",
      "Y[7,1] = <gurobi.Var y[7,1] (value 1.0)>\n",
      "Y[7,5] = <gurobi.Var y[7,5] (value 1.0)>\n",
      "Y[7,24] = <gurobi.Var y[7,24] (value 1.0)>\n",
      "Y[7,54] = <gurobi.Var y[7,54] (value 1.0)>\n",
      "Y[7,74] = <gurobi.Var y[7,74] (value 1.0)>\n",
      "Y[8,2] = <gurobi.Var y[8,2] (value 1.0)>\n",
      "Y[8,3] = <gurobi.Var y[8,3] (value 1.0)>\n",
      "Y[8,6] = <gurobi.Var y[8,6] (value 1.0)>\n",
      "Y[8,16] = <gurobi.Var y[8,16] (value 1.0)>\n",
      "Y[8,82] = <gurobi.Var y[8,82] (value 1.0)>\n",
      "Y[9,0] = <gurobi.Var y[9,0] (value 1.0)>\n",
      "Y[9,1] = <gurobi.Var y[9,1] (value 1.0)>\n",
      "Y[9,23] = <gurobi.Var y[9,23] (value 1.0)>\n",
      "Y[9,43] = <gurobi.Var y[9,43] (value 1.0)>\n",
      "Y[10,0] = <gurobi.Var y[10,0] (value 1.0)>\n",
      "Y[10,1] = <gurobi.Var y[10,1] (value 1.0)>\n",
      "Y[10,2] = <gurobi.Var y[10,2] (value 1.0)>\n",
      "Y[10,3] = <gurobi.Var y[10,3] (value 1.0)>\n",
      "Y[10,4] = <gurobi.Var y[10,4] (value 1.0)>\n",
      "Y[10,5] = <gurobi.Var y[10,5] (value 1.0)>\n",
      "Y[10,6] = <gurobi.Var y[10,6] (value 1.0)>\n",
      "Y[10,7] = <gurobi.Var y[10,7] (value 1.0)>\n",
      "Y[10,8] = <gurobi.Var y[10,8] (value 1.0)>\n",
      "Y[10,9] = <gurobi.Var y[10,9] (value 1.0)>\n",
      "Y[10,10] = <gurobi.Var y[10,10] (value 1.0)>\n",
      "Y[10,11] = <gurobi.Var y[10,11] (value 1.0)>\n",
      "Y[10,12] = <gurobi.Var y[10,12] (value 1.0)>\n",
      "Y[10,13] = <gurobi.Var y[10,13] (value 1.0)>\n",
      "Y[10,14] = <gurobi.Var y[10,14] (value 1.0)>\n",
      "Y[10,15] = <gurobi.Var y[10,15] (value 1.0)>\n",
      "Y[10,16] = <gurobi.Var y[10,16] (value 1.0)>\n",
      "Y[10,17] = <gurobi.Var y[10,17] (value 1.0)>\n",
      "Y[10,18] = <gurobi.Var y[10,18] (value 1.0)>\n",
      "Y[10,19] = <gurobi.Var y[10,19] (value 1.0)>\n",
      "Y[10,20] = <gurobi.Var y[10,20] (value 1.0)>\n",
      "Y[10,21] = <gurobi.Var y[10,21] (value 1.0)>\n",
      "Y[10,22] = <gurobi.Var y[10,22] (value 1.0)>\n",
      "Y[10,23] = <gurobi.Var y[10,23] (value 1.0)>\n",
      "Y[10,24] = <gurobi.Var y[10,24] (value 1.0)>\n",
      "Y[10,25] = <gurobi.Var y[10,25] (value 1.0)>\n",
      "Y[10,26] = <gurobi.Var y[10,26] (value 1.0)>\n",
      "Y[10,27] = <gurobi.Var y[10,27] (value 1.0)>\n",
      "Y[10,28] = <gurobi.Var y[10,28] (value 1.0)>\n",
      "Y[10,29] = <gurobi.Var y[10,29] (value 1.0)>\n",
      "Y[10,30] = <gurobi.Var y[10,30] (value 1.0)>\n",
      "Y[10,31] = <gurobi.Var y[10,31] (value 1.0)>\n",
      "Y[10,32] = <gurobi.Var y[10,32] (value 1.0)>\n",
      "Y[10,33] = <gurobi.Var y[10,33] (value 1.0)>\n",
      "Y[10,34] = <gurobi.Var y[10,34] (value 1.0)>\n",
      "Y[10,35] = <gurobi.Var y[10,35] (value 1.0)>\n",
      "Y[10,36] = <gurobi.Var y[10,36] (value 1.0)>\n",
      "Y[10,37] = <gurobi.Var y[10,37] (value 1.0)>\n",
      "Y[10,38] = <gurobi.Var y[10,38] (value 1.0)>\n",
      "Y[10,39] = <gurobi.Var y[10,39] (value 1.0)>\n",
      "Y[10,40] = <gurobi.Var y[10,40] (value 1.0)>\n",
      "Y[10,41] = <gurobi.Var y[10,41] (value 1.0)>\n",
      "Y[10,42] = <gurobi.Var y[10,42] (value 1.0)>\n",
      "Y[10,43] = <gurobi.Var y[10,43] (value 1.0)>\n",
      "Y[10,44] = <gurobi.Var y[10,44] (value 1.0)>\n",
      "Y[10,45] = <gurobi.Var y[10,45] (value 1.0)>\n",
      "Y[10,46] = <gurobi.Var y[10,46] (value 1.0)>\n",
      "Y[10,47] = <gurobi.Var y[10,47] (value 1.0)>\n",
      "Y[10,48] = <gurobi.Var y[10,48] (value 1.0)>\n",
      "Y[10,49] = <gurobi.Var y[10,49] (value 1.0)>\n",
      "Y[10,50] = <gurobi.Var y[10,50] (value 1.0)>\n",
      "Y[10,51] = <gurobi.Var y[10,51] (value 1.0)>\n",
      "Y[10,52] = <gurobi.Var y[10,52] (value 1.0)>\n",
      "Y[10,53] = <gurobi.Var y[10,53] (value 1.0)>\n",
      "Y[10,54] = <gurobi.Var y[10,54] (value 1.0)>\n",
      "Y[10,55] = <gurobi.Var y[10,55] (value 1.0)>\n",
      "Y[10,56] = <gurobi.Var y[10,56] (value 1.0)>\n",
      "Y[10,57] = <gurobi.Var y[10,57] (value 1.0)>\n",
      "Y[10,58] = <gurobi.Var y[10,58] (value 1.0)>\n",
      "Y[10,59] = <gurobi.Var y[10,59] (value 1.0)>\n",
      "Y[10,60] = <gurobi.Var y[10,60] (value 1.0)>\n",
      "Y[10,61] = <gurobi.Var y[10,61] (value 1.0)>\n",
      "Y[10,62] = <gurobi.Var y[10,62] (value 1.0)>\n",
      "Y[10,63] = <gurobi.Var y[10,63] (value 1.0)>\n",
      "Y[10,64] = <gurobi.Var y[10,64] (value 1.0)>\n",
      "Y[10,65] = <gurobi.Var y[10,65] (value 1.0)>\n",
      "Y[10,66] = <gurobi.Var y[10,66] (value 1.0)>\n",
      "Y[10,67] = <gurobi.Var y[10,67] (value 1.0)>\n",
      "Y[10,68] = <gurobi.Var y[10,68] (value 1.0)>\n",
      "Y[10,69] = <gurobi.Var y[10,69] (value 1.0)>\n",
      "Y[10,70] = <gurobi.Var y[10,70] (value 1.0)>\n",
      "Y[10,71] = <gurobi.Var y[10,71] (value 1.0)>\n",
      "Y[10,72] = <gurobi.Var y[10,72] (value 1.0)>\n",
      "Y[10,73] = <gurobi.Var y[10,73] (value 1.0)>\n",
      "Y[10,74] = <gurobi.Var y[10,74] (value 1.0)>\n",
      "Y[10,75] = <gurobi.Var y[10,75] (value 1.0)>\n",
      "Y[10,76] = <gurobi.Var y[10,76] (value 1.0)>\n",
      "Y[10,77] = <gurobi.Var y[10,77] (value 1.0)>\n",
      "Y[10,78] = <gurobi.Var y[10,78] (value 1.0)>\n",
      "Y[10,79] = <gurobi.Var y[10,79] (value 1.0)>\n",
      "Y[10,80] = <gurobi.Var y[10,80] (value 1.0)>\n",
      "Y[10,81] = <gurobi.Var y[10,81] (value 1.0)>\n",
      "Y[10,82] = <gurobi.Var y[10,82] (value 1.0)>\n",
      "Y[10,83] = <gurobi.Var y[10,83] (value 1.0)>\n",
      "Y[10,84] = <gurobi.Var y[10,84] (value 1.0)>\n",
      "Y[10,85] = <gurobi.Var y[10,85] (value 1.0)>\n",
      "Y[10,86] = <gurobi.Var y[10,86] (value 1.0)>\n",
      "Y[10,87] = <gurobi.Var y[10,87] (value 1.0)>\n",
      "Y[10,88] = <gurobi.Var y[10,88] (value 1.0)>\n",
      "Y[10,89] = <gurobi.Var y[10,89] (value 1.0)>\n",
      "Y[10,90] = <gurobi.Var y[10,90] (value 1.0)>\n",
      "Y[10,91] = <gurobi.Var y[10,91] (value 1.0)>\n",
      "Y[10,92] = <gurobi.Var y[10,92] (value 1.0)>\n",
      "Y[10,93] = <gurobi.Var y[10,93] (value 1.0)>\n",
      "Y[10,94] = <gurobi.Var y[10,94] (value 1.0)>\n",
      "Y[10,95] = <gurobi.Var y[10,95] (value 1.0)>\n",
      "Y[10,96] = <gurobi.Var y[10,96] (value 1.0)>\n",
      "Y[10,97] = <gurobi.Var y[10,97] (value 1.0)>\n",
      "Y[10,98] = <gurobi.Var y[10,98] (value 1.0)>\n",
      "Y[10,99] = <gurobi.Var y[10,99] (value 1.0)>\n",
      "\n",
      "Optimal objective value: 4292938.0\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "if model.status == gp.GRB.OPTIMAL:\n",
    "    print(\"\\nOptimization successful!\")\n",
    "    # print_full_output()\n",
    "    print_concise_output()\n",
    "    print(f\"\\nOptimal objective value: {model.objVal}\")\n",
    "    OPTIMAL_SOLUTION = model.ObjVal\n",
    "elif model.status == gp.GRB.INFEASIBLE:\n",
    "    print(\"Model is infeasible.\")\n",
    "elif model.status == gp.GRB.UNBOUNDED:\n",
    "    print(\"Model is unbounded.\")\n",
    "else:\n",
    "    print(f\"Optimization ended with status {model.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13b29c",
   "metadata": {},
   "source": [
    "---\n",
    "# Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c355ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common\n",
    "def compute_obj_func(x):\n",
    "    return sum(latency[e][s]*reqs[e][v]*x[e,s,v] for e in endpoint_index for s in server_index for v in video_index)\n",
    "\n",
    "x_sol = []\n",
    "y_sol = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09de88",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d547ffa",
   "metadata": {},
   "source": [
    "### 1. place video with highest request number in nearest cache when possible and place all videos for the endpoint in the order that we get\n",
    "order video by request number, and for every endpoint retrieven from this ordered list place all its requested videos in best available caches for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "039aa21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6347627.0 - GAP: 47.86207021857758% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs.extend((e, v) for v in sorted_vs)\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) \n",
    "y = np.zeros(((num_server+1), num_video)) \n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req in sorted_reqs:\n",
    "    req_endpoint = req[E_IND]\n",
    "    req_video = req[V_IND]\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9e886",
   "metadata": {},
   "source": [
    "### 2. place video with highest request number in nearest cache + round robin (every iteration change endpoint)\n",
    "order video by request number, use a round robin schedulo to choose an endpoint retrieven from this ordered list and place its remaining requested video in best available cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0775a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 7091338.0 - GAP: 65.18612661072673% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = defaultdict(list)\n",
    "for e in range(len(reqs)):\n",
    "    sorted_vs = sorted(\n",
    "        [v for v in reqs[e] if reqs[e][v] != 0],\n",
    "        key=lambda v: reqs[e][v],\n",
    "        reverse=True\n",
    "    )\n",
    "    sorted_reqs[e] = sorted_vs\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "Done = False\n",
    "endpoints_req_index = [0 for _ in server_index]\n",
    "while not Done:\n",
    "    Done = True\n",
    "    for curr_endpoint in endpoint_index:\n",
    "        curr_endpoint_req_index = endpoints_req_index[curr_endpoint]\n",
    "        \n",
    "        if curr_endpoint_req_index < len(sorted_reqs[curr_endpoint]):\n",
    "            Done = False # There could still be reqs not satisfied other than this\n",
    "            req_video = sorted_reqs[curr_endpoint][curr_endpoint_req_index]\n",
    "            req_video_size = video_size[req_video]\n",
    "\n",
    "            for curr_cache_index in sorted_latency[curr_endpoint]:\n",
    "                if y[curr_cache_index, req_video]:\n",
    "                    x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                        curr_capacity[curr_cache_index] -= req_video_size\n",
    "                        y[curr_cache_index, req_video] = 1\n",
    "                        x[curr_endpoint, curr_cache_index, req_video] = 1\n",
    "                        break\n",
    "                    \n",
    "        endpoints_req_index[curr_endpoint] += 1\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87489dbd",
   "metadata": {},
   "source": [
    "### 3. place video with highest request number in nearest cache when possible\n",
    "(only order by request number without considering the endpoints, pratically place cache video in the best server order by request number withouth reasoning on endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e34ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 6776093.0 - GAP: 57.842787387099456% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "sorted_reqs = sorted(\n",
    "    [(e, v) for e in range(len(reqs)) for v in reqs[e] if reqs[e][v] != 0],\n",
    "    key=lambda pair: reqs[pair[0]][pair[1]],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "y = np.zeros(((num_server+1), num_video))\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "for req_endpoint,req_video in sorted_reqs:\n",
    "    req_video_size = video_size[req_video]\n",
    "\n",
    "    for curr_cache_index in sorted_latency[req_endpoint]:\n",
    "        if y[curr_cache_index, req_video]:\n",
    "            x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "            break\n",
    "        else:\n",
    "            if curr_capacity[curr_cache_index] > req_video_size:\n",
    "                curr_capacity[curr_cache_index] -= req_video_size\n",
    "                y[curr_cache_index, req_video] = 1\n",
    "                x[req_endpoint, curr_cache_index, req_video] = 1\n",
    "                break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dd1d5",
   "metadata": {},
   "source": [
    "### 4. Place video ordered by popularity in cache with most connected endpoints for that video\n",
    "Order video by request number and place ordered video in the cache connected with most endpoints that have requested that specific video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa52075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9816241.0 - GAP: 128.66020892917624% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "video_req_count = [0 for _ in video_index]\n",
    "num_connected_endpoint = defaultdict(lambda: defaultdict(int)) # used to find best cache to place a video [server][video][latency sum / num endpoint / score]\n",
    "\n",
    "for curr_endpoint_index, endpoint_reqs in reqs.items():\n",
    "    for curr_video_index, req_num in endpoint_reqs.items():\n",
    "        if req_num: # check if requests from endpoint for the video exists\n",
    "            video_req_count[curr_video_index] += req_num\n",
    "            for curr_server_index, lat in latency[curr_endpoint_index].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    num_connected_endpoint[curr_server_index][curr_video_index] += 1\n",
    "            \n",
    "sorted_video_indexes = sorted(range(num_video), key=lambda i: video_req_count[i], reverse=True)\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "# print(curr_capacity)\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    # Sort v indices by ascending value for this e\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "for curr_video_index in sorted_video_indexes:\n",
    "    # now sort caches to get the ones with most connected endpoints that have requested video curr_video_index\n",
    "    for curr_server_index in sorted(\n",
    "        [\n",
    "            i\n",
    "            for i in range(len(num_connected_endpoint))\n",
    "            if num_connected_endpoint[i][curr_video_index]!= 0\n",
    "        ],\n",
    "        key=lambda i: num_connected_endpoint[i][curr_video_index],\n",
    "        reverse=True\n",
    "    ):\n",
    "        if not y[curr_server_index, curr_video_index]:\n",
    "            if curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "                curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "                y[curr_server_index, curr_video_index] = 1\n",
    "                break\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66908d",
   "metadata": {},
   "source": [
    "### 5. place video based on connected endpoint most requested videos\n",
    "for every caches, place their most requested video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702ccb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX RESULT: 9519517.0 - GAP: 121.74829918344965% - OPTIMAL RESULT 4292938.0\n"
     ]
    }
   ],
   "source": [
    "E_IND = 0\n",
    "V_IND = 1\n",
    "\n",
    "# Sort v indexes by descending value for endpoint e\n",
    "sorted_reqs = []\n",
    "sorted_reqs = sorted(\n",
    "    [(e, v) for e in range(len(reqs)) for v in reqs[e] if reqs[e][v] != 0],\n",
    "    key=lambda pair: reqs[pair[0]][pair[1]],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Sort server s latency for endpoint e\n",
    "sorted_latency = defaultdict(list)\n",
    "for e in latency:\n",
    "    sorted_s = sorted(\n",
    "        [s for s in latency[e] if latency[e][s] != 0],\n",
    "        key=lambda s: latency[e][s]\n",
    "    )\n",
    "    sorted_latency[e] = sorted_s\n",
    "\n",
    "\n",
    "# use a list to keep current cache capacity (will be decreased every time a video is placed in cache)\n",
    "curr_capacity = [cache_capacity for _ in range(num_server)]\n",
    "curr_capacity.append(float('inf')) # datacenter doesn't have capacity\n",
    "\n",
    "# create vars (simil guroby, used numpy for efficiency)\n",
    "x = np.zeros((num_endpoint, (num_server+1), num_video)) # e take v from s\n",
    "y = np.zeros(((num_server+1), num_video)) # v is in s\n",
    "y[num_server, :] = 1 # datacenter keep all the videos\n",
    "\n",
    "\n",
    "# get total possible reqs for any cache server from its connected endpoints\n",
    "server_total_reqs = defaultdict(lambda: defaultdict(int))\n",
    "for req_endpoint,req_videos in reqs.items():\n",
    "    for curr_server_index, lat in latency[req_endpoint].items():\n",
    "                if curr_server_index != num_server and lat:\n",
    "                    for curr_video_index in req_videos.keys():\n",
    "                        server_total_reqs[curr_server_index][curr_video_index] += req_videos[curr_video_index]\n",
    "\n",
    "\n",
    "# place video in caches based on request counts\n",
    "for curr_server_index in server_index[:-1]:\n",
    "    sorted_indexes_only = [\n",
    "        video_index\n",
    "        for video_index, count in sorted(\n",
    "            server_total_reqs[curr_server_index].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        if count > 0\n",
    "    ]\n",
    "    for curr_video_index in sorted_indexes_only:\n",
    "        if not y[curr_server_index, curr_video_index] and curr_capacity[curr_server_index] > video_size[curr_video_index]:\n",
    "            curr_capacity[curr_server_index] -= video_size[curr_video_index]\n",
    "            y[curr_server_index, curr_video_index] = 1\n",
    "\n",
    "\n",
    "# iterate trough all reqs to check to what server the endpoint should request the video\n",
    "for req_endpoint,req_videos in reqs.items():    \n",
    "    for curr_video_index in req_videos:\n",
    "        if reqs[req_endpoint][curr_video_index]:\n",
    "            for curr_server_index in sorted_latency[req_endpoint]:\n",
    "                if y[curr_server_index, curr_video_index]:\n",
    "                    x[req_endpoint, curr_server_index, curr_video_index] = 1\n",
    "                    break\n",
    "\n",
    "# print(\"X\")\n",
    "# print(x)\n",
    "# print(\"Y\")\n",
    "# print(y)\n",
    "APPROX_RESULT = compute_obj_func(x)\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - APPROX_RESULT) / OPTIMAL_SOLUTION ) * 100\n",
    "print(f\"APPROX RESULT: {APPROX_RESULT} - GAP: {GAP}% - OPTIMAL RESULT {OPTIMAL_SOLUTION}\")\n",
    "x_sol.append((x, APPROX_RESULT))\n",
    "y_sol.append((y, APPROX_RESULT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63615d",
   "metadata": {},
   "source": [
    "## Local Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0c175",
   "metadata": {},
   "source": [
    "### tabu search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ff2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_x(y):\n",
    "    x = np.zeros((num_endpoint, (num_server+1), num_video))\n",
    "\n",
    "    # Sort server s latency for endpoint e\n",
    "    sorted_latency = defaultdict(list)\n",
    "    for e in latency:\n",
    "        sorted_s = sorted(\n",
    "            [s for s in latency[e] if latency[e][s] != 0],\n",
    "            key=lambda s: latency[e][s]\n",
    "        )\n",
    "        sorted_latency[e] = sorted_s\n",
    "    \n",
    "    for curr_endpoint_index in endpoint_index:\n",
    "        for curr_video_index in reqs[curr_endpoint_index]:\n",
    "            best_server_index = num_server  # default to datacenter\n",
    "            \n",
    "            for curr_server_index in sorted_latency[curr_endpoint_index]:                    \n",
    "                if y[curr_server_index][curr_video_index]:\n",
    "                    best_server_index = curr_server_index\n",
    "                    break\n",
    "\n",
    "            x[curr_endpoint_index][best_server_index][curr_video_index] = 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5369a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_toggle(x, y, num_iters=1000, tabu_list_dim=10, max_no_improve=100):\n",
    "    tabu_list = deque(maxlen=tabu_list_dim)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "    no_improve_count = 0  \n",
    "    \n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                \n",
    "                if move in tabu_list: # ASPIRATION CRITERIA\n",
    "                    if random.random() > 0.2:\n",
    "                        continue\n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                new_y[curr_server_index][curr_video_index] = 1 - new_y[curr_server_index][curr_video_index]\n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "            no_improve_count = 0 # reset no consecutive improvement counter\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            \n",
    "        if no_improve_count >= max_no_improve:\n",
    "            # print(f\"Early stopping after {no_improve_count} iterations without improvement.\")\n",
    "            break\n",
    "        \n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # INTENSIFICATION CRITERIA\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136e156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search_add(x, y, num_iters=1000, tabu_list_dim=10, max_no_improve=100):\n",
    "    tabu_list = deque(maxlen=tabu_list_dim)\n",
    "    intensification_list = []\n",
    "    \n",
    "    # Start with initial solution\n",
    "    best_x = np.copy(x)\n",
    "    best_y = np.copy(y)\n",
    "    best_obj_val = compute_obj_func(best_x)\n",
    "    no_improve_count = 0  \n",
    "    \n",
    "    for iteration in range(num_iters):\n",
    "        neighborhood = []\n",
    "\n",
    "        # Generate neighbor solutions\n",
    "        for curr_server_index in server_index[:-1]:  # Only cache servers\n",
    "            for curr_video_index in video_index:\n",
    "                move = (curr_server_index, curr_video_index)\n",
    "                \n",
    "                if move in tabu_list: # ASPIRATION CRITERIA\n",
    "                    if random.random() > 0.2:\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                # Try toggling video v in cache s\n",
    "                new_y = np.copy(y)\n",
    "                \n",
    "                # Try adding current video in current server if not already present\n",
    "                if new_y[curr_server_index][curr_video_index]:\n",
    "                    continue\n",
    "                new_y[curr_server_index][curr_video_index] = 1 \n",
    "\n",
    "                # Check cache capacity constraint\n",
    "                curr_video_size = sum(video_size[v] for v in video_index if new_y[curr_server_index][v])\n",
    "                if curr_video_size > cache_capacity:\n",
    "                    continue\n",
    "\n",
    "                # Generate new x according to new y\n",
    "                new_x = get_best_x(new_y)\n",
    "\n",
    "                obj_val = compute_obj_func(new_x)\n",
    "\n",
    "                neighborhood.append((obj_val, new_x, new_y, move))\n",
    "\n",
    "        if not neighborhood:\n",
    "            break\n",
    "\n",
    "        # Choose best neighbor\n",
    "        neighborhood.sort(key=lambda tup: tup[0])  # Sort by delay\n",
    "        obj_val, new_x, new_y, move = neighborhood[0]\n",
    "\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_x = new_x\n",
    "            best_y = new_y\n",
    "            intensification_list.append((best_obj_val, best_x, best_y))\n",
    "            intensification_list = sorted(intensification_list)[:10]  # keep top 10\n",
    "            no_improve_count = 0 # reset no consecutive improvement counter\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            \n",
    "        if no_improve_count >= max_no_improve:\n",
    "            # print(f\"Early stopping after {no_improve_count} iterations without improvement.\")\n",
    "            break\n",
    "\n",
    "        # Update current solution\n",
    "        x = new_x\n",
    "        y = new_y\n",
    "\n",
    "        # Update tabu list\n",
    "        tabu_list.append(move)\n",
    "        \n",
    "        # INTENSIFICATION CRITERIA\n",
    "        if iteration % 70 == 0 and intensification_list:\n",
    "            _, best_x, best_y = random.choice(intensification_list)\n",
    "            x, y = best_x.copy(), best_y.copy()\n",
    "\n",
    "    return best_x, best_y, best_obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a24d4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best sol: 4292938.0\n",
      "\n",
      "old solution: 6347627.0, tabu toggle sol: 6347627.0, new GAP: 47.86207021857758\n",
      "old solution: 6347627.0, tabu add sol: 6347627.0, new GAP: 47.86207021857758\n",
      "\n",
      "old solution: 7091338.0, tabu toggle sol: 7091338.0, new GAP: 65.18612661072673\n",
      "old solution: 7091338.0, tabu add sol: 7091338.0, new GAP: 65.18612661072673\n",
      "\n",
      "old solution: 6776093.0, tabu toggle sol: 6776093.0, new GAP: 57.842787387099456\n",
      "old solution: 6776093.0, tabu add sol: 6776093.0, new GAP: 57.842787387099456\n",
      "\n",
      "old solution: 9816241.0, tabu toggle sol: 7161592.0, new GAP: 66.82262823269286\n",
      "old solution: 9816241.0, tabu add sol: 7275848.0, new GAP: 69.48411554045272\n",
      "\n",
      "old solution: 9519517.0, tabu toggle sol: 9013457.0, new GAP: 109.96010191621681\n",
      "old solution: 9519517.0, tabu add sol: 9511795.0, new GAP: 121.56842237181155\n"
     ]
    }
   ],
   "source": [
    "print(f\"best sol: {OPTIMAL_SOLUTION}\")\n",
    "tabu_list_dim = np.floor(np.sqrt(num_req_descriptions))\n",
    "\n",
    "for sol_index in range(len(x_sol)):\n",
    "    default_obj_val = compute_obj_func(x_sol[sol_index][0])\n",
    "    GAP_DEF = ( abs(OPTIMAL_SOLUTION - default_obj_val) / OPTIMAL_SOLUTION ) * 100\n",
    "\n",
    "    \n",
    "    x_tabu_toggle, y_tabu_toggle, obj_tabu_toggle = tabu_search_toggle(x_sol[sol_index][0], y_sol[sol_index][0], num_iters=700, tabu_list_dim=int(tabu_list_dim))\n",
    "    GAP_TOGGLE = ( abs(OPTIMAL_SOLUTION - obj_tabu_toggle) / OPTIMAL_SOLUTION ) * 100\n",
    "    print(f\"\\nold solution: {default_obj_val}, tabu toggle sol: {obj_tabu_toggle}, new GAP: {GAP_TOGGLE}\")\n",
    "    \n",
    "    x_tabu_add, y_tabu_add, obj_tabu_add = tabu_search_add(x_sol[sol_index][0], y_sol[sol_index][0], num_iters=700, tabu_list_dim=int(tabu_list_dim))\n",
    "    GAP_ADD = ( abs(OPTIMAL_SOLUTION - obj_tabu_add) / OPTIMAL_SOLUTION ) * 100\n",
    "    print(f\"old solution: {default_obj_val}, tabu add sol: {obj_tabu_add}, new GAP: {GAP_ADD}\")\n",
    "    \n",
    "    if obj_tabu_toggle < obj_tabu_add:\n",
    "        if obj_tabu_toggle < default_obj_val:\n",
    "            x_sol.append((x_tabu_toggle, obj_tabu_toggle))\n",
    "            y_sol.append((y_tabu_toggle, obj_tabu_toggle))\n",
    "    else:\n",
    "        if obj_tabu_add < default_obj_val:\n",
    "            x_sol.append((x_tabu_add, obj_tabu_add))\n",
    "            y_sol.append((y_tabu_add, obj_tabu_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7701ef4",
   "metadata": {},
   "source": [
    "## Genetic algorithm\n",
    "\n",
    "#### fitness: minimize delay ( compute_obj_func(x) )\n",
    "#### initial population: heuristics solutions (x_sol & y_sol)\n",
    "#### randomization: montecarlo simulation\n",
    "#### crossover & mutation: on y (update x conseguently get_best_x(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59a5db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_in_generation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0566772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 0., 0., 1.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 1., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [1., 1., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 1., 1., 1.]]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 1.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 1., ..., 0., 0., 0.],\n",
      "       [1., 1., 0., ..., 0., 0., 0.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]]), np.float64(5236789.0))\n"
     ]
    }
   ],
   "source": [
    "X_IND = 0\n",
    "Y_IND = 1\n",
    "OBJ_IND = 2\n",
    "\n",
    "NUM_GEN = 400\n",
    "NUM_CROSSOVER_TRIAL = 60\n",
    "NUM_DEAD = 3\n",
    "MUT_RATE = 0.001\n",
    "\n",
    "def is_feasible(y):\n",
    "    for curr_server_index in server_index[:-1]:\n",
    "        # calculate total used space by video placed on cache curr_server_index\n",
    "        curr_tot_size = sum(video_size[curr_video_index] for curr_video_index in video_index if y[curr_server_index, curr_video_index])\n",
    "        if curr_tot_size > cache_capacity:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def montecarlo_roulette_individual_selection(current_population, reverse=False):\n",
    "    # Reverse = True: dead selection - Reverse = False: parent selection\n",
    "    if reverse:\n",
    "        fitness_list = [ curr_individual[OBJ_IND] for curr_individual in current_population ]\n",
    "    else:\n",
    "        # 1 / obj func because less delay will have bigger size\n",
    "        fitness_list = [ (1/curr_individual[OBJ_IND]) for curr_individual in current_population ]\n",
    "        \n",
    "    fitness_tot = sum(fitness_list)\n",
    "    \n",
    "    spin = random.uniform(0, fitness_tot)\n",
    "    \n",
    "    curr_fit = 0\n",
    "    for curr_individual_index in range(len(current_population)):\n",
    "        curr_fit += fitness_list[curr_individual_index]\n",
    "        if spin < curr_fit:\n",
    "            \n",
    "            if reverse:\n",
    "                return curr_individual_index\n",
    "            \n",
    "            return current_population[curr_individual_index]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    # we need to clone parent or python will reference to them (and if we do mutation we'll do it also on parents)\n",
    "    y1 = parent1[Y_IND].copy()\n",
    "    y2 = parent2[Y_IND].copy()\n",
    "    \n",
    "    childs_y = []\n",
    "    childs = []\n",
    "    \n",
    "    # Monosplit crossover\n",
    "    split = np.random.randint(1, num_server)\n",
    "    # take y cache configuration [0 to split] from parent 1 and remaining cache configuration [split to num_server+1] from parent2 \n",
    "    childs_y.append( np.vstack([y1[:split, :], y2[split:, :]]) )\n",
    "    childs_y.append( np.vstack([y1[:split, :], y2[split:, :]]) )\n",
    "    \n",
    "    for child_y in childs_y:\n",
    "        child_x = get_best_x(child_y)\n",
    "        childs.append((child_x, child_y, compute_obj_func(child_x)))\n",
    "    \n",
    "    return childs\n",
    "\n",
    "def mutate(childs):\n",
    "\n",
    "    childs_mutated = []\n",
    "    \n",
    "    for child in childs:\n",
    "        child_mutated = cp.deepcopy(child)\n",
    "        \n",
    "        for curr_server_index in server_index[:-1]:\n",
    "            for curr_video_index in video_index:\n",
    "                \n",
    "                # mutation is a toggle in y matrix\n",
    "                if random.random() < MUT_RATE:\n",
    "                    child_mutated[Y_IND][curr_server_index][curr_video_index] = 1 - child_mutated[Y_IND][curr_server_index][curr_video_index] \n",
    "        \n",
    "        # check if mutated child is feasible, otherwise keep unmutated one\n",
    "        if is_feasible(child_mutated[Y_IND]):\n",
    "            childs_mutated.append(child_mutated)                    \n",
    "        else:\n",
    "            childs_mutated.append(child)                    \n",
    "            \n",
    "    return childs_mutated\n",
    "\n",
    "def start_genetic():\n",
    "    # an individual is (x, y, objective value)\n",
    "    population = [(x_sol[curr_individual_index][0], y_sol[curr_individual_index][0], x_sol[curr_individual_index][1]) for curr_individual_index in range(len(y_sol))]\n",
    "    # print(f\"Starting population: {population}\")\n",
    "    \n",
    "    for current_gen in range(NUM_GEN):\n",
    "        if population:\n",
    "            for _ in range(NUM_CROSSOVER_TRIAL): \n",
    "                parent_1 = montecarlo_roulette_individual_selection(population)\n",
    "                parent_2 = montecarlo_roulette_individual_selection(population)\n",
    "                childs = crossover(parent_1, parent_2)\n",
    "                childs = mutate(childs)\n",
    "                if childs:\n",
    "                    population.extend(childs)\n",
    "            \n",
    "            # remove an individual every iteration\n",
    "            # for _ in range(NUM_DEAD):\n",
    "            serial_killer_num = len(population) // 15 # floor of 10% of population\n",
    "            for _ in range(serial_killer_num):\n",
    "                dead = montecarlo_roulette_individual_selection(population, reverse=True)\n",
    "                tomb = population.pop(dead)\n",
    "                \n",
    "            if population:\n",
    "                # print(f\"Death individual: {dead} - {tomb}\")\n",
    "                best = min(population, key=lambda individual: individual[OBJ_IND])\n",
    "                best_in_generation_history.append(best[OBJ_IND])\n",
    "                # print(f\"Gen {current_gen}: Best delay = {best[OBJ_IND]}\")\n",
    "        else:\n",
    "            return \"GENOCIDE\"\n",
    "        \n",
    "        \n",
    "    return min(population, key=lambda individual: individual[OBJ_IND])\n",
    "\n",
    "sol = start_genetic()\n",
    "best_in_generation_history.append(sol[OBJ_IND])\n",
    "print(f\"{sol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "143591f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Solution GAP: 21.98613164224594\n"
     ]
    }
   ],
   "source": [
    "# PLOT performance\n",
    "best_start = min(x_sol, key=lambda solution: solution[1])\n",
    "GAP = ( abs(OPTIMAL_SOLUTION - best_in_generation_history[-1]) / OPTIMAL_SOLUTION ) * 100\n",
    "GAP_START = ( abs(OPTIMAL_SOLUTION - best_start[1]) / OPTIMAL_SOLUTION ) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(best_in_generation_history, linestyle='-', color=\"m\", label=\"Crossover\")\n",
    "plt.axhline(y=float(best_start[1]), linestyle='--', color=\"y\", label=\"Best Starting Solution\") \n",
    "plt.axhline(y=OPTIMAL_SOLUTION, color='r', linestyle='--', label='Optimal Solution')\n",
    "\n",
    "# best solution GAP\n",
    "plt.plot(len(best_in_generation_history) - 1, best_in_generation_history[-1], marker='D', markersize=10, color='rebeccapurple')\n",
    "plt.text(len(best_in_generation_history) - 10, best_in_generation_history[-1] + 80000,  f'{round(GAP,1)}%', color='rebeccapurple', va='bottom', ha='left')\n",
    "\n",
    "# starting solution GAP\n",
    "plt.plot(1, best_start[1], marker='D', markersize=10, color='darkgoldenrod')\n",
    "plt.text(-9, best_start[1] - 200000,  f'{round(GAP_START,1)}%', color='darkgoldenrod', va='bottom', ha='left')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Crossover\")\n",
    "plt.title(\"Crossover over generations\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Genetic Solution GAP: {GAP}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
